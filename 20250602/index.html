<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>åˆè¯†Pytorch(äºŒ) -- ç¥ç»ç½‘ç»œæ­å»º | æ«è½ç¹èŠ±</title><meta name="keywords" content="Pytorch,Python,Deep Learning"><meta name="author" content="yeximm"><meta name="copyright" content="yeximm"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="åˆè¯†Pytorch(äºŒ) -- ç¥ç»ç½‘ç»œæ­å»º"><meta name="application-name" content="åˆè¯†Pytorch(äºŒ) -- ç¥ç»ç½‘ç»œæ­å»º"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="åˆè¯†Pytorch(äºŒ) -- ç¥ç»ç½‘ç»œæ­å»º"><meta property="og:url" content="https://www.dyeddie.top/20250602/index.html"><meta property="og:site_name" content="æ«è½ç¹èŠ±"><meta property="og:description" content="Pytorchæ­å»ºç¥ç»ç½‘ç»œæ­¥éª¤ï¼Œå¸¸ç”¨å±‚çº§çš„ä½¿ç”¨ï¼Œç½‘ç»œæ¨¡å‹ä½¿ç”¨ã€ä¿å­˜ã€åŠ è½½"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.dyeddie.top/source_fig/articles/20250602%E5%88%9D%E8%AF%86Pytorch(%E4%BA%8C)/110119t32pt.jpg"><meta property="article:author" content="yeximm"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://www.dyeddie.top/source_fig/articles/20250602%E5%88%9D%E8%AF%86Pytorch(%E4%BA%8C)/110119t32pt.jpg"><meta name="description" content="Pytorchæ­å»ºç¥ç»ç½‘ç»œæ­¥éª¤ï¼Œå¸¸ç”¨å±‚çº§çš„ä½¿ç”¨ï¼Œç½‘ç»œæ¨¡å‹ä½¿ç”¨ã€ä¿å­˜ã€åŠ è½½"><link rel="shortcut icon" href="/source_fig/favicon.png"><link rel="canonical" href="https://www.dyeddie.top/20250602/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//static.cloudflareinsights.com"/><link rel="preconnect" href="//www.clarity.ms"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/@fortawesome/fontawesome-free@7.1.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@6.1.6/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?34e134fb3c7108fe3f44bc4e6f57c1f8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-3RZJMX45BS"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-3RZJMX45BS');
</script><script defer="defer" data-pjax="data-pjax" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;38de068f639745a0a8b37427ef001545&quot;}"></script><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "ur2tuu2ccl");</script><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: undefined,
  postHeadAiDescription: undefined,
  diytitle: undefined,
  LA51: undefined,
  greetingBox: undefined,
  twikooEnvId: '',
  commentBarrageConfig:undefined,
  music_page_default: "nav_music",
  root: '/',
  preloader: undefined,
  friends_vue_info: undefined,
  navMusic: false,
  mainTone: {"mode":"api","api":"https://img2color-go.vercel.app/api?img=","cover_change":true},
  authorStatus: undefined,
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"ç¹","msgToSimplifiedChinese":"ç®€","rightMenuMsgToTraditionalChinese":"è½¬ä¸ºç¹ä½“","rightMenuMsgToSimplifiedChinese":"è½¬ä¸ºç®€ä½“"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":360},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶é”™è¯¯',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: true,
    simplehomepage: false,
    post: true
  },
  runtime: 'å¤©',
  date_suffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"ä½ å·²åˆ‡æ¢ä¸ºç¹ä½“","cht_to_chs":"ä½ å·²åˆ‡æ¢ä¸ºç®€ä½“","day_to_night":"ä½ å·²åˆ‡æ¢ä¸ºæ·±è‰²æ¨¡å¼","night_to_day":"ä½ å·²åˆ‡æ¢ä¸ºæµ…è‰²æ¨¡å¼","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.2.0/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.2.0/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: 'æ«è½ç¹èŠ±',
  title: 'åˆè¯†Pytorch(äºŒ) -- ç¥ç»ç½‘ç»œæ­å»º',
  postAI: '',
  pageFillDescription: '1 ç¥ç»ç½‘ç»œåŸºæœ¬éª¨æ¶, 1.1 éª¨æ¶ Containers, 1.1.1 Moduleçš„ä½¿ç”¨, 1.1.2 æ¨¡å‹æ­å»º Sequential, 1.2 å·ç§¯å±‚ Convolution Layers, 1.2.1 nn.functional.conv2d, 1.2.2 nn.Conv2d, 1.3 æ± åŒ–å±‚ Pooling layers, 1.3.1 nn.MaxPool2d, 1.3.2 æœ€å¤§æ± åŒ–ä½œç”¨, 1.4.1 ReLUå‡½æ•°, 1.4.2 Sigmoidå‡½æ•°, 1.5 æŸå¤±å‡½æ•° Loss Functions, 2 åå‘ä¼ æ’­ backward, 3 ä¼˜åŒ–å™¨ optim, 4 ç°æœ‰ç½‘ç»œæ¨¡å‹, 4.1 VGGåˆ†ç±»æ¨¡å‹, 4.2 æŸ¥çœ‹VGGæ¨¡å‹æ¶æ„, 4.3 ä¿®æ”¹ç½‘ç»œæ¨¡å‹, 5 æ¨¡å‹ä¿å­˜ä¸åŠ è½½, 5.1 ä¿å­˜æ¨¡å‹ç»“æ„(å‚æ•°), 5.2 æ¨¡å‹åŠ è½½ç¥ç»ç½‘ç»œåŸºæœ¬éª¨æ¶å…³äºç¥ç»ç½‘ç»œçš„å·¥å…·ä¸»è¦åœ¨ä¸­å®˜ç½‘æ–‡æ¡£ä¸»è¦ç»™ç¥ç»ç½‘ç»œå®šä¹‰äº†ä¸€äº›éª¨æ¶ç»“æ„å¾€ç»“æ„ä¸­æ·»åŠ ä¸åŒçš„å†…å®¹å°±å¯ä»¥ç»„æˆç¥ç»ç½‘ç»œå·ç§¯å±‚æ± åŒ–å±‚å¡«å……å±‚éçº¿æ€§æ¿€æ´»æ ‡å‡†åŒ–å½’ä¸€åŒ–å±‚éª¨æ¶åŒ…å«ä¸ªæ¨¡å—æ˜¯æœ€å¸¸ç”¨çš„æ¨¡å—ç»™æ‰€æœ‰ç¥ç»ç½‘ç»œæä¾›ä¸€ä¸ªåŸºæœ¬çš„éª¨æ¶çš„ä½¿ç”¨åˆ›å»ºè‡ªå®šä¹‰æ¨¡å‹éœ€è¦ç»§æ‰¿è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–å‡½æ•°å‰å‘ä¼ æ’­å®ä¾‹åŒ–æ¨¡å‹å¯¹è±¡è®¾å®šè¾“å…¥å€¼è°ƒç”¨æ¨¡å‹è¿ç®—æ¨¡å‹æ­å»ºæŒ‰ç…§é¡ºåºæ‰§è¡Œæ¨¡å‹ä¸­çš„å„é¡¹åŠŸèƒ½ä»¥çš„ç»“æ„ä¸ºä¾‹ä¸ä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡å‹ç»“æ„è¿‡ç¨‹æ¨¡å‹è¾“å‡ºç»“æœæŸ¥çœ‹æµ‹è¯•æ•°æ®ä½¿ç”¨ç»„å»ºç¥ç»ç½‘ç»œæ¨¡å‹æ¨¡å‹è¾“å‡ºç»“æœæŸ¥çœ‹æµ‹è¯•æ•°æ®ä½¿ç”¨å¯è§†åŒ–æ¨¡å‹æ¶æ„å·ç§¯å±‚æ˜¯å¯¹çš„ä¸€ä¸ªå°è£…è¡¨ç¤ºä¸€ç»´è¡¨ç¤ºäºŒç»´å›¾ç‰‡æ˜¯è¡¨ç¤ºä¸‰ç»´å·ç§¯æ“ä½œå¯è§†åŒ–ç”¨æ³•æ³¨æ„æ•°æ®è¦ä½¿ç”¨æ ¼å¼è¾“å…¥å½¢çŠ¶è¦æ±‚æƒé‡å·ç§¯æ ¸å½¢çŠ¶è¦æ±‚åç½®å½¢çŠ¶è¦æ±‚é»˜è®¤å€¼æ­¥é•¿å·ç§¯æ ¸æ¯æ¬¡ç§»åŠ¨æ­¥é•¿å·ç§¯ä¸­è¦æ±‚é•¿å®½å¯ä»¥æ˜¯å•ä¸ªæ•°å­—æˆ–ä¸€ä¸ªå…ƒç»„é»˜è®¤æ˜¯å¡«å……åœ¨è¾“å…¥å›¾åƒçš„å·¦å³ä¸¤è¾¹è¿›è¡Œå¡«å……å†³å®šå¡«å……å¤šå¤§èŒƒå›´å¯ä»¥æ˜¯å•ä¸ªæ•°å­—æˆ–ä¸€ä¸ªå…ƒç»„é»˜è®¤æ˜¯ä¸å¡«å……å¦‚æœä¸å¡«å……ç™½è¾¹é‚£ä¹ˆè¾¹ç¼˜çš„å›¾åƒç‰¹å¾å°±ä¼šç¼ºå¤±ç¤ºä¾‹ä»£ç è¾“å…¥å›¾åƒå·ç§¯æ ¸å°±æ˜¯æƒé‡ä¸ºé€šé“æ­¥é•¿ä¸ºæ­¥é•¿ä¸ºç”¨æ³•å¸¸ç”¨çš„äº”ä¸ªå‚æ•°è¾“å…¥å›¾åƒä¸­çš„é€šé“æ•°å·ç§¯åè¾“å‡ºçš„é€šé“æ•°å·ç§¯æ ¸çš„å¤§å°ä¸€ä¸ªæ•°å­—æ—¶ä¸ºå¤§å°çš„å·ç§¯æ ¸ä¸è§„åˆ™æ ¸è®¾ç½®ä¸ºè¡Œå®½å·ç§¯çš„æ­¥é•¿å·ç§¯ä¸­è¦æ±‚é•¿å®½å¯ä»¥æ˜¯å•ä¸ªæ•°å­—æˆ–ä¸€ä¸ªå…ƒç»„é»˜è®¤æ˜¯åœ¨è¾“å…¥çš„å››ä¸ªè¾¹ä¸Šæ·»åŠ å¡«å……å†³å®šå¡«å……å¤šå¤§èŒƒå›´é»˜è®¤æ˜¯ä¸å¡«å……é€‰æ‹©å¡«å……çš„æ—¶å€™æŒ‰ä»€ä¹ˆæ¨¡å¼è¿›è¡Œå¡«å……é»˜è®¤å†…æ ¸å…ƒç´ ä¹‹é—´çš„é—´è·é»˜è®¤æ˜¯ä»è¾“å…¥é€šé“åˆ°è¾“å‡ºé€šé“çš„é˜»å¡è¿æ¥æ•°é»˜è®¤æ˜¯ä¸ºæ—¶å‘è¾“å‡ºæ·»åŠ å¯å­¦ä¹ çš„åå·®é»˜è®¤ä»£ç å®ä¾‹è‡ªå®šä¹‰æ¨¡å‹å®Œæˆçˆ¶ç±»åˆå§‹åŒ–ä½¿ç”¨å¯è§†åŒ–æ¨¡å‹ç»“æœè¾“å…¥å›¾åƒè¾“å‡ºæ˜¯é€šé“ä¿®æ”¹ä¸ºé€šé“è¿›è¡Œæ˜¾ç¤ºå·ç§¯å±‚è¯´æ˜å¦‚ä¸‹å›¾æ‰€ç¤ºè¾“å…¥å›¾åƒæ˜¯ç»è¿‡ä¸€ä¸ªå·ç§¯å’Œéçº¿æ€§æ¿€æ´»åå˜æˆè¾“å‡ºå±‚çš„é«˜å®½è®¡ç®—å…¬å¼è§å®˜æ–¹æ–‡æ¡£æ± åŒ–å±‚æœ€å¤§æ± åŒ–ä¹Ÿç§°ä¸ºä¸‹é‡‡æ ·ä¸Šé‡‡æ ·å¹³å‡æ± åŒ–è‡ªé€‚åº”çš„æœ€å¤§æ± åŒ–è®¾ç½®ç”¨æ¥å–æœ€å¤§å€¼çš„çª—å£å°ºå¯¸ç±»ä¼¼å·ç§¯æ ¸è®¾ç½®ä¸ºçš„æ—¶å€™ä¼šç”Ÿæˆä¸€ä¸ªçš„çª—å£çª—å£çš„æ­¥é•¿é»˜è®¤ä¸ºåœ¨ä¸¤ä¾§æ·»åŠ å¡«å……çª—å£ä¸­å„å…ƒç´ ä¹‹é—´çš„æ­¥é•¿ä¸ºæ—¶è¿”å›æœ€å¤§ç´¢å¼•å’Œè¾“å‡ºç”¨äºä¹‹åä¸ºæ—¶ä½¿ç”¨è€Œä¸æ˜¯æ¥è®¡ç®—è¾“å‡ºå½¢çŠ¶å¯¹ç¼ºå¤±ä¿¡æ¯éƒ¨åˆ†ä¹Ÿè¿›è¡Œä¸Šé‡‡æ ·ä¼šå¯¹ç¼ºå¤±ä¿¡æ¯éƒ¨åˆ†è¿›è¡Œèˆå¼ƒå‘ä¸‹å–æ•´å‘ä¸Šå–æ•´å¦‚ä¸‹å›¾æ‰€ç¤ºå®ä¾‹ä»£ç å˜å½¢ä¸ºé€šé“æ•°é•¿å®½æœ€å¤§æ± åŒ–ä½œç”¨æœ€å¤§æ± åŒ–çš„ç›®çš„æ˜¯ä¿ç•™è¾“å…¥çš„ç‰¹å¾åŒæ—¶æŠŠæ•°æ®é‡å‡å°é€šè¿‡å¯è§†åŒ–æœ€å¤§æ± åŒ–æ•ˆæœéçº¿æ€§æ¿€æ´»éçº¿æ€§æ¿€æ´»ä¸»è¦ä¸ºäº†ç»™ç¥ç»ç½‘ç»œå¼•å…¥éçº¿æ€§çš„ç‰¹å¾å¸¸è§çš„æœ‰å‡½æ•°è¾“å…¥å¤§äºæ—¶è¾“å‡ºåŸå€¼å°äºæ—¶è¾“å‡ºå‡½æ•°é€šè¿‡å…¬å¼è®¡ç®—è¾“å‡ºç»“æœåœ¨èŒƒå›´å†…å¸¸ç”¨äºäºŒåˆ†ç±»é—®é¢˜å‡½æ•°æ–‡æ¡£åœ°å€ä¸ºæ—¶ä¼šå°†è¾“å…¥å†…å­˜åœ°å€çš„æ•°æ®ç›´æ¥æ”¹å˜å°±æ˜¯åŸåœ°æ“ä½œæ— éœ€è¿”å›å€¼ä¸ºæ—¶ä¿ç•™åŸå§‹æ•°æ®éœ€è¦é‡‡ç”¨è¿”å›å€¼çš„å½¢å¼æ¥æ”¶æ”¹å˜åçš„æ•°æ®å®ä¾‹ä»£ç è¾“å…¥æ·»åŠ ä¸Šå‚æ•°å›¾åƒæ˜¯ç»´çš„é«˜å®½éƒ½æ˜¯å‡½æ•°æ–‡æ¡£åœ°å€ä½¿ç”¨å¯è§†åŒ–ç»“æœæŸå¤±å‡½æ•°è®¡ç®—å®é™…è¾“å‡ºå’Œç›®æ ‡ä¹‹é—´çš„å·®è·ä¸ºæ›´æ–°è¾“å‡ºæä¾›ä¸€å®šçš„ä¾æ®åå‘ä¼ æ’­æ–‡æ¡£åœ°å€å‡½æ•°å·²å¼ƒç”¨è¯·å‚é˜…é»˜è®¤æƒ…å†µä¸‹æŸå¤±æŒ‰æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæŸå¤±å…ƒç´ è¿›è¡Œå¹³å‡è¯·æ³¨æ„å¯¹äºæŸäº›æŸå¤±æ¯ä¸ªæ ·æœ¬éƒ½æœ‰å¤šä¸ªå…ƒç´ å¦‚æœå­—æ®µè®¾ç½®ä¸ºåˆ™å°†æ¯ä¸ªå°æ‰¹é‡çš„æŸå¤±ç›¸åŠ å½“ä¸ºæ—¶å¿½ç•¥é»˜è®¤å€¼å·²å¼ƒç”¨å‚è§é»˜è®¤æƒ…å†µä¸‹æ ¹æ®å¯¹æ¯ä¸ªå°æ‰¹é‡çš„è§‚æµ‹å€¼è¿›è¡Œå¹³å‡æˆ–æ±‚å’Œå½“ä¸ºæ—¶è¿”å›æ¯ä¸ªæ‰¹å¤„ç†å…ƒç´ çš„æŸå¤±å¹¶å¿½ç•¥é»˜è®¤å€¼æŒ‡å®šè¦åº”ç”¨äºè¾“å‡ºçš„ç¼©å‡è¡¨ç¤ºå’Œä¸åº”ç”¨ç¼©å‡è¾“å‡ºçš„æ€»å’Œå°†é™¤ä»¥è¾“å‡ºä¸­çš„å…ƒç´ æ•°é‡è¾“å‡ºå°†è¢«æ±‚å’Œæ³¨æ„å’Œæ­£åœ¨è¢«å¼ƒç”¨åŒæ—¶æŒ‡å®šè¿™ä¸¤ä¸ªå‚æ•°ä¸­çš„ä»»ä½•ä¸€ä¸ªéƒ½å°†è¦†ç›–é»˜è®¤å€¼å®ä¾‹ä»£ç å˜æˆé€šé“è¡Œåˆ—å‡½æ•°è®¡ç®—å¹³æ–¹å·®å‡½æ•°å®ä¾‹ä»£ç å˜æˆé€šé“è¡Œåˆ—å‡½æ•°äº¤å‰ç†µå‡½æ•°å®ä¾‹ä»£ç æœ‰ç±»å˜ä¸ºç±»åˆ«æ•°åå‘ä¼ æ’­ä½¿ç”¨å‡½æ•°å®ç°åå‘ä¼ æ’­è®¡ç®—ç¥ç»ç½‘ç»œä¸­æ¯ä¸ªèŠ‚ç‚¹è¦æ›´æ–°çš„å‚æ•°éƒ½æœ‰ä¸€ä¸ªæ¢¯åº¦æ ¹æ®æ¢¯åº¦å¯¹å‚æ•°è¿›è¡Œä¼˜åŒ–æœ€ç»ˆå®ç°é™ä½çš„ç›®çš„è¾“å‡ºæœ‰ä¸ªæ•°å€¼æ¯ä¸€ä¸ªä»£è¡¨æ¯ä¸ªç±»çš„æ¦‚ç‡å›¾ç‰‡çš„ç±»åˆ«ç¼–å·äº¤å‰ç†µå‡½æ•°å¼€å¯è®¡ç®—æ¢¯åº¦ç”¨æ¥è®¡ç®—æ¢¯åº¦éœ€è¦ä½¿ç”¨åˆé€‚çš„ä¼˜åŒ–å™¨å»æ›´æ–°å‚æ•°ä»¥è¾¾åˆ°æ•´ä½“çš„è¯¯å·®é™ä½çš„ç›®çš„ä¼˜åŒ–å™¨æ–‡æ¡£åœ°å€æ¨¡å‹çš„å‚æ•°å­¦ä¹ é€Ÿç‡æ„é€ ä¼˜åŒ–å™¨é¦–å…ˆåœ¨ä¼˜åŒ–å™¨ä¸­æ”¾å…¥æ¨¡å‹çš„å‚æ•°ä¼˜åŒ–æ­¥éª¤å¦‚ä¸‹æ¢¯åº¦æ¸…é›¶è®¡ç®—è¾“å‡ºä¸çœŸå®å€¼çš„è¯¯å·®å¾—åˆ°æ¯ä¸ªè¦æ›´æ–°å‚æ•°çš„æ¢¯åº¦æ¯ä¸ªå‚æ•°éƒ½æ ¹æ®ä¸Šæ­¥çš„æ¢¯åº¦è¿›è¡Œä¼˜åŒ–å®ä¾‹ä»£ç æ„å»ºè‡ªå®šä¹‰æ¨¡å‹å¼•å…¥æ•°æ®é›†å®ä¾‹åŒ–æ¨¡å‹å°†æ•°æ®ç§»è‡³è®¡ç®—å¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨å®šä¹‰ä¼˜åŒ–å™¨è¾“å‡ºæœ‰ä¸ªæ•°å€¼æ¯ä¸€ä¸ªä»£è¡¨æ¯ä¸ªç±»çš„æ¦‚ç‡å›¾ç‰‡çš„ç±»åˆ«ç¼–å·äº¤å‰ç†µå‡½æ•°æ¢¯åº¦æ¸…é›¶ä¸Šä¸€æ¬¡çš„æ¢¯åº¦å¯¹è¿™ä¸€æ¬¡çš„æ¢¯åº¦æ›´æ–°æ²¡æœ‰ç”¨å¾—åˆ°æ¯ä¸ªå¯ä»¥è°ƒèŠ‚å‚æ•°å¯¹åº”çš„æ¢¯åº¦å¯¹æ¯ä¸ªå‚æ•°è¿›è¡Œè°ƒä¼˜æ•´ä½“è¯¯å·®æ±‚å’Œç°æœ‰ç½‘ç»œæ¨¡å‹æ–‡æ¡£åœ°å€æ˜¯å…³äºå›¾åƒç›¸å…³çš„æ¨¡å‹æ˜¯å…³äºè¯­éŸ³ç›¸å…³çš„æ¨¡å‹æ˜¯å…³äºæ–‡å­—ç›¸å…³çš„æ¨¡å‹åˆ†ç±»æ¨¡å‹å¸¸ç”¨çš„æœ‰ä½¿ç”¨å·²ç»ä¸‹è½½å¥½çš„çš„é¢„è®­ç»ƒæƒé‡å‚é˜…é»˜è®¤æƒ…å†µä¸‹ä¸ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æƒé‡å¦‚æœä¸ºåˆ™æ˜¾ç¤ºä¸‹è½½åˆ°çš„è¿›åº¦æ¡é»˜è®¤å€¼ä¸ºä¼ é€’ç»™çš„å‚æ•°æ›´å¤šè¯¦ç»†ä¿¡æ¯å‚é˜…æŸ¥çœ‹æ¨¡å‹æ¶æ„ä¸ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æŸ¥çœ‹ä¸è®­ç»ƒæ¨¡å‹çš„æ¶æ„æ¨¡å‹æ¶æ„ä¿®æ”¹ç½‘ç»œæ¨¡å‹æ¨¡å‹é€šè¿‡æ•°æ®é›†è®­ç»ƒæœ€ç»ˆåˆ†ç±»ç±»åˆ«æœ‰ä¸ªæ•°æ®é›†ä¸­åªæœ‰å„ç±»åˆ«çš„æ•°æ®å¦‚ä½•åˆ©ç”¨ç°æœ‰çš„ç½‘ç»œå»æ”¹åŠ¨å®ƒçš„ç»“æ„åœ¨ç½‘ç»œæœ€åæ·»åŠ ä¸€ä¸ªå±‚çº§åœ¨æ¨¡å‹æœ«å°¾æ·»åŠ å±‚çº§åœ¨æ¨¡å—æœ€åæ·»åŠ ä¸€ä¸ªå±‚çº§ä¿®æ”¹æŸä¸ªå±‚çº§å‚æ•°è°ƒæ•´æ¨¡å—ä¸­ç¬¬å±‚å‚æ•°æ¨¡å‹ä¿å­˜ä¸åŠ è½½ä¿å­˜æ¨¡å‹ç»“æ„å‚æ•°åˆå§‹åŒ–æ¨¡å‹ä¿å­˜æ–¹å¼ä¿å­˜æ¨¡å‹ç»“æ„æ¨¡å‹å‚æ•°ä¿å­˜æ–¹å¼æŠŠæ¨¡å‹çš„å‚æ•°ä¿å­˜æˆå­—å…¸å®˜æ–¹æ¨èæ¨¡å‹åŠ è½½æ–¹å¼ä¿å­˜æ–¹å¼åŠ è½½æ¨¡å‹æ–¹å¼ä¿å­˜æ–¹å¼åŠ è½½æ¨¡å‹åŠ è½½æ¨¡å‹æƒé‡è¯»å–å‡ºæ¥å­—å…¸å½¢å¼',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-12-26 21:15:22',
  postMainColor: '#967d86',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 8.1.1"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><a id="site-name" href="/" accesskey="h"><div class="title">æ«è½ç¹èŠ±</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> æ–‡ç« </span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="fa-solid fa-layer-group faa-tada"></i><span> ç±»åˆ«</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="fa-solid fa-tag faa-tada"></i><span> æ ‡ç­¾</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> è§£å‹</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/apps/"><i class="fa-solid fa-icons faa-tada"></i><span> ä¿®ä»™å®¤</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> æˆ‘çš„</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="fa-solid fa-eject faa-tada"></i><span> å…³äº</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="éšæœºå‰å¾€ä¸€ä¸ªæ–‡ç« " href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="æœç´¢ğŸ”" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> æœç´¢</span></a></div><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" alt="å¾®ä¿¡" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png"/></a><div class="post-qr-code-desc">å¾®ä¿¡</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="æ”¯ä»˜å®" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"/></a><div class="post-qr-code-desc">æ”¯ä»˜å®</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">å…´è¶£ç‚¹</div><span class="author-content-item-title">å¯»æ‰¾ä½ æ„Ÿå…´è¶£çš„é¢†åŸŸ</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/ArchLinux/" style="font-size: 1.05rem;">ArchLinux<sup>1</sup></a><a href="/tags/GitHub/" style="font-size: 1.05rem;">GitHub<sup>2</sup></a><a href="/tags/Linux/" style="font-size: 1.05rem;">Linux<sup>5</sup></a><a href="/tags/Numpy/" style="font-size: 1.05rem;">Numpy<sup>1</sup></a><a href="/tags/Oral-Practice/" style="font-size: 1.05rem;">Oral_Practice<sup>2</sup></a><a href="/tags/Python/" style="font-size: 1.05rem;">Python<sup>1</sup></a><a href="/tags/Pytorch/" style="font-size: 1.05rem;">Pytorch<sup>4</sup></a><a href="/tags/Skills/" style="font-size: 1.05rem;">Skills<sup>1</sup></a><a href="/tags/Sublime-Text/" style="font-size: 1.05rem;">Sublime_Text<sup>1</sup></a><a href="/tags/Ubuntu/" style="font-size: 1.05rem;">Ubuntu<sup>2</sup></a><a href="/tags/Xfce/" style="font-size: 1.05rem;">Xfce<sup>1</sup></a><a href="/tags/conda%E5%91%BD%E4%BB%A4/" style="font-size: 1.05rem;">condaå‘½ä»¤<sup>1</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>æ–‡ç« </span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>å½’æ¡£</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/06/"><span class="card-archive-list-date">å…­æœˆ 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">4</span><span>ç¯‡</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">ä¹æœˆ 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>ç¯‡</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">å…«æœˆ 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">8</span><span>ç¯‡</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">å…­æœˆ 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>ç¯‡</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">å››æœˆ 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>ç¯‡</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="æ˜¾ç¤ºæ¨¡å¼åˆ‡æ¢" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="è¾¹æ æ˜¾ç¤ºæ§åˆ¶"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="åˆ‡æ¢"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">åŸåˆ›</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url">æ·±åº¦å­¦ä¹ </a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/Pytorch/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>Pytorch</span></a></span></div></div><h1 class="post-title" itemprop="name headline">åˆè¯†Pytorch(äºŒ) -- ç¥ç»ç½‘ç»œæ­å»º</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="post-meta-icon anzhiyufont anzhiyu-icon-history"></i><span class="post-meta-label">æ›´æ–°äº</span><time itemprop="dateCreated datePublished" datetime="2025-12-26T13:15:22.422Z" title="æ›´æ–°äº 2025-12-26 21:15:22">2025-12-26</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="æ–‡ç« å­—æ•°"></i><span class="post-meta-label" title="æ–‡ç« å­—æ•°">å­—æ•°æ€»è®¡:</span><span class="word-count" title="æ–‡ç« å­—æ•°">4.5k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="é˜…è¯»æ—¶é•¿"></i><span class="post-meta-label" title="é˜…è¯»æ—¶é•¿">é˜…è¯»æ—¶é•¿:</span><span>21åˆ†é’Ÿ</span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="ä½œè€…IPå±åœ°ä¸ºå—äº¬"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>å—äº¬</span></div></div></div><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="/../source_fig/articles/20250602%E5%88%9D%E8%AF%86Pytorch(%E4%BA%8C)/110119t32pt.jpg"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="https://www.dyeddie.top/20250602/"><header><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url">æ·±åº¦å­¦ä¹ </a><a href="/tags/Pytorch/" tabindex="-1" itemprop="url">Pytorch</a><h1 id="CrawlerTitle" itemprop="name headline">åˆè¯†Pytorch(äºŒ) -- ç¥ç»ç½‘ç»œæ­å»º</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">yeximm</span><time itemprop="dateCreated datePublished" datetime="2025-12-26T13:15:22.422Z" title="undefined 2025-12-26 21:15:22">2025-12-26</time></header><h1 id="1-ç¥ç»ç½‘ç»œåŸºæœ¬éª¨æ¶">1 ç¥ç»ç½‘ç»œåŸºæœ¬éª¨æ¶</h1>
<p>pytorchå…³äºç¥ç»ç½‘ç»œçš„å·¥å…·ä¸»è¦åœ¨torch.nnä¸­ï¼ˆNeural Networkï¼‰</p>
<p>å®˜ç½‘æ–‡æ¡£ï¼š<a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/nn.html">https://docs.pytorch.org/docs/stable/nn.html</a></p>
<ul>
<li><p>Containers #
ä¸»è¦ç»™ç¥ç»ç½‘ç»œå®šä¹‰äº†ä¸€äº›éª¨æ¶ï¼ˆç»“æ„ï¼‰ï¼Œå¾€ç»“æ„ä¸­æ·»åŠ ä¸åŒçš„å†…å®¹å°±å¯ä»¥ç»„æˆç¥ç»ç½‘ç»œ</p></li>
<li><p>Convolution Layers # å·ç§¯å±‚</p></li>
<li><p>Pooling layers # æ± åŒ–å±‚</p></li>
<li><p>Padding Layers # å¡«å……å±‚</p></li>
<li><p>Non-linear Activations (weighted sum, nonlinearity) #
éçº¿æ€§æ¿€æ´»</p></li>
<li><p>Non-linear Activations (other)</p></li>
<li><p>Normalization Layers # æ ‡å‡†åŒ–ï¼ˆå½’ä¸€åŒ–ï¼‰å±‚</p></li>
<li><p>â€¦</p></li>
</ul>
<h2 id="11-éª¨æ¶-containers">1.1 éª¨æ¶ Containers</h2>
<p>ContainersåŒ…å«6ä¸ªæ¨¡å—ï¼Œ<a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">Module</a>æ˜¯æœ€å¸¸ç”¨çš„æ¨¡å—ï¼Œç»™<strong>æ‰€æœ‰</strong>ç¥ç»ç½‘ç»œæä¾›ä¸€ä¸ªåŸºæœ¬çš„éª¨æ¶</p>
<table>
<thead>
<tr>
<th><a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">Module</a></th>
<th>Base class for all neural network modules.</th>
</tr>
</thead>
<tbody>
<tr>
<td><a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential">Sequential</a></td>
<td>A sequential container.</td>
</tr>
<tr>
<td><a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList">ModuleList</a></td>
<td>Holds submodules in a list.</td>
</tr>
<tr>
<td><a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict">ModuleDict</a></td>
<td>Holds submodules in a dictionary.</td>
</tr>
<tr>
<td><a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ParameterList.html#torch.nn.ParameterList">ParameterList</a></td>
<td>Holds parameters in a list.</td>
</tr>
<tr>
<td><a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict">ParameterDict</a></td>
<td>Holds parameters in a dictionary.</td>
</tr>
</tbody>
</table>
<h3 id="111-moduleçš„ä½¿ç”¨">1.1.1 Moduleçš„ä½¿ç”¨</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TdModel</span>(nn.Module):    <span class="comment"># åˆ›å»ºè‡ªå®šä¹‰æ¨¡å‹ï¼Œéœ€è¦ç»§æ‰¿nn.Module</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()   <span class="comment"># è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–å‡½æ•°</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">20</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):       <span class="comment"># å‰å‘ä¼ æ’­</span></span><br><span class="line">        output = x + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">td = TdModel()    <span class="comment"># å®ä¾‹åŒ–æ¨¡å‹å¯¹è±¡</span></span><br><span class="line">x = torch.tensor(<span class="number">1.0</span>)     <span class="comment"># è®¾å®šè¾“å…¥å€¼</span></span><br><span class="line">output = td(x)            <span class="comment"># è°ƒç”¨æ¨¡å‹è¿ç®—</span></span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<h3 id="112-æ¨¡å‹æ­å»º-sequential">1.1.2 æ¨¡å‹æ­å»º Sequential</h3>
<p>æŒ‰ç…§é¡ºåºæ‰§è¡Œpytorchæ¨¡å‹ä¸­çš„å„é¡¹åŠŸèƒ½ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Using Sequential to create a small model. When `model` is run,</span></span><br><span class="line"><span class="comment"># input will first be passed to `Conv2d(1,20,5)`. The output of</span></span><br><span class="line"><span class="comment"># `Conv2d(1,20,5)` will be used as the input to the first</span></span><br><span class="line"><span class="comment"># `ReLU`; the output of the first `ReLU` will become the input</span></span><br><span class="line"><span class="comment"># for `Conv2d(20,64,5)`. Finally, the output of</span></span><br><span class="line"><span class="comment"># `Conv2d(20,64,5)` will be used as input to the second `ReLU`</span></span><br><span class="line">model = nn.Sequential(</span><br><span class="line">          nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using Sequential with OrderedDict. This is functionally the</span></span><br><span class="line"><span class="comment"># same as the above code</span></span><br><span class="line">model = nn.Sequential(OrderedDict([</span><br><span class="line">          (<span class="string">&#x27;conv1&#x27;</span>, nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">&#x27;relu1&#x27;</span>, nn.ReLU()),</span><br><span class="line">          (<span class="string">&#x27;conv2&#x27;</span>, nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">&#x27;relu2&#x27;</span>, nn.ReLU())</span><br><span class="line">        ]))</span><br></pre></td></tr></table></figure>

<p>ä»¥ CIFAR 10 çš„ç»“æ„ä¸ºä¾‹</p>
<p><img
src="../source_fig/articles/20250602åˆè¯†Pytorch(äºŒ)/image-20250604103242875.png"
alt="image-20250604103242875" /></p>
<p><strong>ä¸ä½¿ç”¨ Sequential</strong> ï¼Œç¥ç»ç½‘ç»œæ¨¡å‹ç»“æ„è¿‡ç¨‹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TdModule</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TdModule, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.maxpool1 = nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.maxpool2 = nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv3 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.maxpool3 = nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.flatten = nn.Flatten()</span><br><span class="line">        <span class="variable language_">self</span>.linear1 = nn.Linear(<span class="number">1024</span>, <span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.linear2 = nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.maxpool1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.maxpool2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv3(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.maxpool3(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.flatten(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.linear1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.linear2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">td = TdModule()</span><br><span class="line"><span class="built_in">print</span>(td)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ¨¡å‹è¾“å‡ºç»“æœæŸ¥çœ‹</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">64</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)    <span class="comment"># æµ‹è¯•æ•°æ®</span></span><br><span class="line">output = td(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.size())</span><br></pre></td></tr></table></figure>

<p><strong>ä½¿ç”¨ Sequential</strong> ç»„å»ºç¥ç»ç½‘ç»œæ¨¡å‹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TdModule</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TdModule, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.model1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">td = TdModule()</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ¨¡å‹è¾“å‡ºç»“æœæŸ¥çœ‹</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">64</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)    <span class="comment"># æµ‹è¯•æ•°æ®</span></span><br><span class="line">output = td(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.size())</span><br></pre></td></tr></table></figure>

<p>ä½¿ç”¨ <strong>tensotboard å¯è§†åŒ–</strong>æ¨¡å‹æ¶æ„</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;logs&#x27;</span>)</span><br><span class="line">writer.add_graph(TdModule(), <span class="built_in">input</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h2 id="12-å·ç§¯å±‚-convolution-layers">1.2 å·ç§¯å±‚ Convolution Layers</h2>
<p><strong>torch.nn</strong>æ˜¯å¯¹<strong>torch.nn.functional</strong>çš„ä¸€ä¸ªå°è£…</p>
<p><a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d">nn.Conv1d</a>è¡¨ç¤ºä¸€ç»´ï¼Œ<a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">nn.Conv2d</a>è¡¨ç¤ºäºŒç»´ï¼ˆå›¾ç‰‡æ˜¯2Dï¼‰ï¼Œ<a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d">nn.Conv3d</a>è¡¨ç¤ºä¸‰ç»´</p>
<p>å·ç§¯æ“ä½œå¯è§†åŒ–ï¼š<a
target="_blank" rel="noopener" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md</a></p>
<h3 id="121-nnfunctionalconv2d">1.2.1 nn.functional.conv2d</h3>
<p><a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html#torch.nn.functional.conv2d">torch.nn.functional.conv2d</a><strong>ç”¨æ³•</strong>ï¼Œæ³¨æ„æ•°æ®è¦ä½¿ç”¨tensoræ ¼å¼ï¼ï¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.functional.conv2d(</span><br><span class="line">    <span class="built_in">input</span>, weight, bias=<span class="literal">None</span>, stride=<span class="number">1</span>, </span><br><span class="line">    padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span></span><br><span class="line">) </span><br></pre></td></tr></table></figure>

<ul>
<li><strong>input</strong> è¾“å…¥ï¼Œå½¢çŠ¶è¦æ±‚
(minibatch,in_channels,iH,iW)</li>
<li><strong>weight</strong> æƒé‡ / å·ç§¯æ ¸ï¼Œå½¢çŠ¶è¦æ±‚
(out_channels,in_channelsgroups,kH,kW)</li>
<li><strong>bias</strong> åç½®ï¼Œå½¢çŠ¶è¦æ±‚
(out_channels)(out_channels)ï¼Œé»˜è®¤å€¼ï¼šNone</li>
<li><strong>stride</strong>
æ­¥é•¿ï¼Œå·ç§¯æ ¸æ¯æ¬¡ç§»åŠ¨æ­¥é•¿ï¼Œ2då·ç§¯ä¸­è¦æ±‚é•¿å®½ï¼Œå¯ä»¥æ˜¯å•ä¸ªæ•°å­—æˆ–ä¸€ä¸ªå…ƒç»„
(sH, sW)ï¼Œé»˜è®¤æ˜¯1</li>
<li><strong>padding</strong>
å¡«å……ï¼Œåœ¨è¾“å…¥å›¾åƒçš„å·¦å³ä¸¤è¾¹è¿›è¡Œå¡«å……ï¼Œpaddingå†³å®šå¡«å……å¤šå¤§èŒƒå›´ï¼Œå¯ä»¥æ˜¯å•ä¸ªæ•°å­—æˆ–ä¸€ä¸ªå…ƒç»„
(padH, padW)ï¼Œé»˜è®¤æ˜¯0ï¼ˆä¸å¡«å……ï¼‰
<ul>
<li>å¦‚æœä¸å¡«å……ç™½è¾¹ï¼Œé‚£ä¹ˆè¾¹ç¼˜çš„å›¾åƒç‰¹å¾å°±ä¼šç¼ºå¤±</li>
</ul></li>
</ul>
<p><strong>ç¤ºä¾‹ä»£ç </strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.tensor(       <span class="comment"># è¾“å…¥å›¾åƒ</span></span><br><span class="line">    [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">     [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">     [<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">     [<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">     [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]]</span><br><span class="line">)</span><br><span class="line">kernel = torch.tensor(      <span class="comment"># å·ç§¯æ ¸ï¼Œå°±æ˜¯æƒé‡weight</span></span><br><span class="line">    [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">     [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">     [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>]]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.reshape(<span class="built_in">input</span>, (<span class="number">1</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>))     <span class="comment"># minibatchä¸º1ï¼Œ1é€šé“ï¼Œ5H*5W</span></span><br><span class="line">kernel = torch.reshape(kernel, (<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">output = F.conv2d(<span class="built_in">input</span>, kernel, stride=<span class="number">1</span>)    <span class="comment"># æ­¥é•¿ä¸º1</span></span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line">output = F.conv2d(<span class="built_in">input</span>, kernel, stride=<span class="number">2</span>)    <span class="comment"># æ­¥é•¿ä¸º2</span></span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<h3 id="122-nnconv2d">1.2.2 nn.Conv2d</h3>
<p><a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">nn.Conv2d</a>ç”¨æ³•</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Conv2d(</span><br><span class="line">    in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, <span class="comment"># å¸¸ç”¨çš„äº”ä¸ªå‚æ•°</span></span><br><span class="line">    dilation=<span class="number">1</span>, groups=<span class="number">1</span>, bias=<span class="literal">True</span>, padding_mode=<span class="string">&#x27;zeros&#x27;</span>, </span><br><span class="line">    device=<span class="literal">None</span>, dtype=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>in_channels</strong> (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>)
â€“ è¾“å…¥å›¾åƒä¸­çš„é€šé“æ•°</li>
<li><strong>out_channels</strong> (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>)
â€“ å·ç§¯åè¾“å‡ºçš„é€šé“æ•°</li>
<li><strong>kernel_size</strong> (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>
<em>or</em> <a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a>)
â€“
å·ç§¯æ ¸çš„å¤§å°ï¼Œä¸€ä¸ªæ•°å­—æ—¶ä¸º<strong>n*n</strong>å¤§å°çš„å·ç§¯æ ¸ï¼Œä¸è§„åˆ™æ ¸è®¾ç½®ä¸º
<strong>(è¡Œ, å®½)</strong></li>
<li><strong>stride</strong> (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>
<em>or</em> <a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,
optional</em>) â€“ å·ç§¯çš„æ­¥é•¿ï¼Œ2då·ç§¯ä¸­è¦æ±‚é•¿å®½ï¼Œå¯ä»¥æ˜¯å•ä¸ªæ•°å­—æˆ–ä¸€ä¸ªå…ƒç»„
(sH, sW)ï¼Œé»˜è®¤æ˜¯1</li>
<li><strong>padding</strong> (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em>
<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a>
<em>or</em> <a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,
optional</em>) â€“
åœ¨è¾“å…¥çš„å››ä¸ªè¾¹ä¸Šæ·»åŠ å¡«å……ï¼Œpaddingå†³å®šå¡«å……å¤šå¤§èŒƒå›´ï¼Œé»˜è®¤æ˜¯0ï¼ˆä¸å¡«å……ï¼‰</li>
<li><strong>padding_mode</strong> (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,
optional</em>) â€“é€‰æ‹©paddingå¡«å……çš„æ—¶å€™ï¼ŒæŒ‰ä»€ä¹ˆæ¨¡å¼è¿›è¡Œå¡«å…… â€˜zerosâ€™,
â€˜reflectâ€™, â€˜replicateâ€™ or â€˜circularâ€™. é»˜è®¤: â€˜zerosâ€™</li>
<li><strong>dilation</strong> (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>
<em>or</em> <a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,
optional</em>) â€“ å†…æ ¸å…ƒç´ ä¹‹é—´çš„é—´è·ï¼Œé»˜è®¤æ˜¯1</li>
<li><strong>groups</strong> (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,
optional</em>) â€“ ä»è¾“å…¥é€šé“åˆ°è¾“å‡ºé€šé“çš„é˜»å¡è¿æ¥æ•°ï¼Œé»˜è®¤æ˜¯1</li>
<li><strong>bias</strong> (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,
optional</em>) â€“ ä¸ºTrueæ—¶å‘è¾“å‡ºæ·»åŠ å¯å­¦ä¹ çš„åå·®ï¼Œé»˜è®¤True</li>
</ul>
<p><strong>ä»£ç å®ä¾‹</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TdModule</span>(nn.Module):    <span class="comment"># è‡ªå®šä¹‰æ¨¡å‹</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TdModule, <span class="variable language_">self</span>).__init__()    <span class="comment"># å®Œæˆçˆ¶ç±»åˆå§‹åŒ–</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">6</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">td = TdModule()</span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./logs&#x27;</span>)    <span class="comment"># ä½¿ç”¨tensorboardå¯è§†åŒ–æ¨¡å‹ç»“æœ</span></span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    output = td(imgs)</span><br><span class="line">    <span class="comment"># print(imgs.shape)   # torch.Size([64, 3, 32, 32])</span></span><br><span class="line">    <span class="comment"># print(output.shape) # torch.Size([64, 6, 30, 30])</span></span><br><span class="line">    writer.add_image(<span class="string">&#x27;input&#x27;</span>, imgs, step, dataformats=<span class="string">&#x27;NCHW&#x27;</span>)   <span class="comment"># è¾“å…¥å›¾åƒ</span></span><br><span class="line">    output = torch.reshape(output, (-<span class="number">1</span>, <span class="number">3</span>, <span class="number">30</span>, <span class="number">30</span>))                      <span class="comment"># è¾“å‡ºæ˜¯6é€šé“ï¼Œä¿®æ”¹ä¸º3é€šé“è¿›è¡Œæ˜¾ç¤º</span></span><br><span class="line">    writer.add_image(<span class="string">&#x27;output&#x27;</span>, output, step, dataformats=<span class="string">&#x27;NCHW&#x27;</span>)</span><br><span class="line">    step += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>å·ç§¯å±‚è¯´æ˜ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p>
<p>è¾“å…¥å›¾åƒæ˜¯ 224 x 224 x 3ï¼Œç»è¿‡ä¸€ä¸ªå·ç§¯å’Œéçº¿æ€§æ¿€æ´»åï¼Œå˜æˆ 224 x 224
x 64</p>
<p>è¾“å‡ºå±‚çš„é«˜å®½è®¡ç®—å…¬å¼è§pytorchå®˜æ–¹æ–‡æ¡£ï¼š<a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d</a></p>
<p><img
src="../source_fig/articles/20250602åˆè¯†Pytorch(äºŒ)/image-20250604103633371.png"
alt="image-20250604103633371" /></p>
<h2 id="13-æ± åŒ–å±‚-pooling-layers">1.3 æ± åŒ–å±‚ Pooling layers</h2>
<p>æœ€å¤§æ± åŒ–ï¼ˆMaxPoolï¼‰ä¹Ÿç§°ä¸ºä¸‹é‡‡æ ·ï¼Œä¸Šé‡‡æ ·ï¼ˆMaxUnpoolï¼‰ï¼Œå¹³å‡æ± åŒ–ï¼ˆAvgPoolï¼‰ï¼Œè‡ªé€‚åº”çš„æœ€å¤§æ± åŒ–ï¼ˆAdaptiveMaxPoolï¼‰</p>
<h3 id="131-nnmaxpool2d">1.3.1 nn.MaxPool2d</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MaxPool2d(</span><br><span class="line">    kernel_size, stride=<span class="literal">None</span>, padding=<span class="number">0</span>, </span><br><span class="line">    dilation=<span class="number">1</span>, return_indices=<span class="literal">False</span>, ceil_mode=<span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>kernel_size (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union"><em>Union</em></a><em>[</em><a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em>
<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>[</em><a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em>
<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>]]</em>)
â€“
è®¾ç½®ç”¨æ¥å–æœ€å¤§å€¼çš„çª—å£å°ºå¯¸ï¼Œç±»ä¼¼å·ç§¯æ ¸ï¼Œè®¾ç½®ä¸º3çš„æ—¶å€™ä¼šç”Ÿæˆä¸€ä¸ª3*3çš„çª—å£</li>
<li>stride (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union"><em>Union</em></a><em>[</em><a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em>
<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>[</em><a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em>
<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>]]</em>)
â€“ çª—å£çš„æ­¥é•¿ï¼Œé»˜è®¤ä¸ºkernel_size</li>
<li>padding (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union"><em>Union</em></a><em>[</em><a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em>
<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>[</em><a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em>
<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>]]</em>)
â€“ åœ¨ä¸¤ä¾§æ·»åŠ å¡«å……</li>
<li>dilation (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union"><em>Union</em></a><em>[</em><a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em>
<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>[</em><a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em>
<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>]]</em>)
â€“ çª—å£ä¸­å„å…ƒç´ ä¹‹é—´çš„æ­¥é•¿</li>
<li>return_indices (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a>)
â€“ ä¸ºTrueæ—¶è¿”å›æœ€å¤§ç´¢å¼•å’Œè¾“å‡ºï¼Œç”¨äº <a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html#torch.nn.MaxUnpool2d">torch.nn.MaxUnpool2d</a>
ä¹‹å</li>
<li>ceil_mode (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a>)
â€“ ä¸ºTrueæ—¶ä½¿ç”¨ ceil <strong>è€Œä¸æ˜¯ floor</strong>
æ¥è®¡ç®—è¾“å‡ºå½¢çŠ¶ï¼Œceilå¯¹ç¼ºå¤±ä¿¡æ¯éƒ¨åˆ†ä¹Ÿè¿›è¡Œä¸Šé‡‡æ ·ï¼Œfloorä¼šå¯¹ç¼ºå¤±ä¿¡æ¯éƒ¨åˆ†è¿›è¡Œèˆå¼ƒ
<ul>
<li>floorå‘ä¸‹å–æ•´ï¼Œceilå‘ä¸Šå–æ•´ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º <img
src="../source_fig/articles/20250602åˆè¯†Pytorch(äºŒ)/image-20250604103717552.png"
alt="image-20250604103717552" /></li>
</ul></li>
</ul>
<p><strong>å®ä¾‹ä»£ç </strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.tensor(</span><br><span class="line">    [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">     [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">     [<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">     [<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">     [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]], dtype=torch.float32</span><br><span class="line">)</span><br><span class="line"><span class="built_in">input</span> = torch.reshape(<span class="built_in">input</span>, (-<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>))     <span class="comment"># å˜å½¢ä¸º[minibatchsizeï¼Œé€šé“æ•°ï¼Œé•¿ï¼Œå®½]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TdModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TdModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.maxpool1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        output = <span class="variable language_">self</span>.maxpool1(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">        </span><br><span class="line">td = TdModel()</span><br><span class="line">output = td(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<h3 id="132-æœ€å¤§æ± åŒ–ä½œç”¨">1.3.2 æœ€å¤§æ± åŒ–ä½œç”¨</h3>
<p>æœ€å¤§æ± åŒ–çš„ç›®çš„æ˜¯ä¿ç•™è¾“å…¥çš„ç‰¹å¾ï¼ŒåŒæ—¶æŠŠæ•°æ®é‡å‡å°</p>
<p>é€šè¿‡tensorboardå¯è§†åŒ–æœ€å¤§æ± åŒ–æ•ˆæœ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader = torch.utils.data.DataLoader(dataset, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.maxpool1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        output = <span class="variable language_">self</span>.maxpool1(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">td = Net()</span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;logs&#x27;</span>)</span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    writer.add_image(<span class="string">&#x27;input&#x27;</span>, imgs, step, dataformats=<span class="string">&#x27;NCHW&#x27;</span>)</span><br><span class="line">    outputs = td(imgs)</span><br><span class="line">    writer.add_image(<span class="string">&#x27;outputs&#x27;</span>, outputs, step, dataformats=<span class="string">&#x27;NCHW&#x27;</span>)</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h2 id="14-éçº¿æ€§æ¿€æ´»-non-linear-activations">1.4 éçº¿æ€§æ¿€æ´» Non-linear
Activations</h2>
<p>éçº¿æ€§æ¿€æ´»ä¸»è¦ä¸ºäº†ç»™ç¥ç»ç½‘ç»œå¼•å…¥éçº¿æ€§çš„ç‰¹å¾ï¼Œå¸¸è§çš„æœ‰ï¼š</p>
<ul>
<li><a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU">ReLU</a>å‡½æ•°ï¼Œè¾“å…¥å¤§äº0æ—¶è¾“å‡ºåŸå€¼ï¼Œå°äº0
æ—¶è¾“å‡º0</li>
<li><a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid">Sigmoid</a>å‡½æ•°ï¼Œé€šè¿‡å…¬å¼è®¡ç®—ï¼Œè¾“å‡ºç»“æœåœ¨
<strong>(0,1)</strong> èŒƒå›´å†…ï¼Œå¸¸ç”¨äºäºŒåˆ†ç±»é—®é¢˜</li>
</ul>
<h3 id="141-reluå‡½æ•°">1.4.1 ReLUå‡½æ•°</h3>
<p>pytorchæ–‡æ¡£åœ°å€ï¼š<a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU">https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.ReLU(inplace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"> <span class="built_in">input</span> = -<span class="number">1</span></span><br><span class="line"> ReLU(<span class="built_in">input</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"> <span class="comment"># input = 0</span></span><br><span class="line"> </span><br><span class="line">output = ReLU(<span class="built_in">input</span>, inplace=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># input = -1</span></span><br><span class="line"><span class="comment"># output = 0</span></span><br></pre></td></tr></table></figure>

<ul>
<li>inplaceä¸ºTrueæ—¶ï¼Œä¼šå°†è¾“å…¥å†…å­˜åœ°å€çš„æ•°æ®ç›´æ¥æ”¹å˜ï¼Œå°±æ˜¯åŸåœ°æ“ä½œï¼Œæ— éœ€è¿”å›å€¼</li>
<li>inplaceä¸ºFalseæ—¶ï¼Œä¿ç•™åŸå§‹æ•°æ®ï¼Œéœ€è¦é‡‡ç”¨è¿”å›å€¼çš„å½¢å¼æ¥æ”¶æ”¹å˜åçš„æ•°æ®</li>
</ul>
<p><strong>å®ä¾‹ä»£ç </strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.tensor(</span><br><span class="line">    [[<span class="number">1</span>, -<span class="number">0.5</span>],</span><br><span class="line">     [-<span class="number">1</span>, <span class="number">3</span>]]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># è¾“å…¥æ·»åŠ ä¸Šbatchsizeå‚æ•°ï¼Œå›¾åƒæ˜¯1ç»´çš„ï¼Œé«˜å®½éƒ½æ˜¯2</span></span><br><span class="line"><span class="built_in">input</span> = torch.reshape(<span class="built_in">input</span>, (-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>))    </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TdModule</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TdModule, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.relu1 = nn.ReLU()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        output = <span class="variable language_">self</span>.relu1(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">Td = TdModule()</span><br><span class="line">output = Td(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<h3 id="142-sigmoidå‡½æ•°">1.4.2 Sigmoidå‡½æ•°</h3>
<p>pytorchæ–‡æ¡£åœ°å€ï¼š<a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid">https://docs.pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Sigmoid(*args, **kwargs)</span><br></pre></td></tr></table></figure>

<p><strong>ä½¿ç”¨tensorboardå¯è§†åŒ–ç»“æœ</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader = torch.utils.data.DataLoader(dataset, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TdModule</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TdModule, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.relu1 = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.sigmoid1 = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        output = <span class="variable language_">self</span>.sigmoid1(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">Td = TdModule()</span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;logs&#x27;</span>)</span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    writer.add_image(<span class="string">&#x27;input&#x27;</span>, imgs, step, dataformats=<span class="string">&#x27;NCHW&#x27;</span>)</span><br><span class="line">    outputs = Td(imgs)</span><br><span class="line">    writer.add_image(<span class="string">&#x27;outputs&#x27;</span>, outputs, step, dataformats=<span class="string">&#x27;NCHW&#x27;</span>)</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h2 id="15-æŸå¤±å‡½æ•°-loss-functions">1.5 æŸå¤±å‡½æ•° Loss Functions</h2>
<ul>
<li>è®¡ç®—å®é™…è¾“å‡ºå’Œç›®æ ‡ä¹‹é—´çš„å·®è·</li>
<li>ä¸ºæ›´æ–°è¾“å‡ºæä¾›ä¸€å®šçš„ä¾æ®ï¼ˆåå‘ä¼ æ’­ï¼‰</li>
</ul>
<p>pytorchæ–‡æ¡£åœ°å€ï¼š<a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/nn.html#loss-functions">https://docs.pytorch.org/docs/stable/nn.html#loss-functions</a></p>
<h3 id="151-l1losså‡½æ•°">1.5.1 <a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss"><strong>L1Loss</strong></a>å‡½æ•°</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.L1Loss(</span><br><span class="line">    size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>size_average (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,
optional</em>) â€“
å·²å¼ƒç”¨ï¼ˆè¯·å‚é˜…reductionï¼‰ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒæŸå¤±æŒ‰æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæŸå¤±å…ƒç´ è¿›è¡Œå¹³å‡ã€‚è¯·æ³¨æ„ï¼Œå¯¹äºæŸäº›æŸå¤±ï¼Œæ¯ä¸ªæ ·æœ¬éƒ½æœ‰å¤šä¸ªå…ƒç´ ã€‚å¦‚æœå­—æ®µsize_maverageè®¾ç½®ä¸ºFalseï¼Œåˆ™å°†æ¯ä¸ªå°æ‰¹é‡çš„æŸå¤±ç›¸åŠ ã€‚å½“reduceä¸ºFalseæ—¶å¿½ç•¥ã€‚é»˜è®¤å€¼ï¼šTrue</li>
<li>reduce (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,
optional</em>) â€“
å·²å¼ƒç”¨ï¼ˆå‚è§reduceï¼‰ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæ ¹æ®size_maverageï¼Œå¯¹æ¯ä¸ªå°æ‰¹é‡çš„è§‚æµ‹å€¼è¿›è¡Œå¹³å‡æˆ–æ±‚å’Œã€‚å½“reduceä¸ºFalseæ—¶ï¼Œè¿”å›æ¯ä¸ªæ‰¹å¤„ç†å…ƒç´ çš„æŸå¤±ï¼Œå¹¶å¿½ç•¥size_maverageã€‚é»˜è®¤å€¼ï¼šTrue</li>
<li>reduction (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,
optional</em>) â€“
æŒ‡å®šè¦åº”ç”¨äºè¾“å‡ºçš„ç¼©å‡ï¼šâ€˜noneâ€™|â€˜è¡¨ç¤ºâ€™|â€˜å’Œâ€™ã€‚â€˜noneâ€™ï¼šä¸åº”ç”¨ç¼©å‡ï¼Œâ€˜meanâ€™ï¼šè¾“å‡ºçš„æ€»å’Œå°†é™¤ä»¥è¾“å‡ºä¸­çš„å…ƒç´ æ•°é‡ï¼Œâ€˜sumâ€™ï¼šè¾“å‡ºå°†è¢«æ±‚å’Œã€‚æ³¨æ„ï¼šsize_maverageå’Œreduceæ­£åœ¨è¢«å¼ƒç”¨ï¼ŒåŒæ—¶ï¼ŒæŒ‡å®šè¿™ä¸¤ä¸ªå‚æ•°ä¸­çš„ä»»ä½•ä¸€ä¸ªéƒ½å°†è¦†ç›–reduceã€‚é»˜è®¤å€¼ï¼šâ€˜meanâ€™</li>
</ul>
<p><strong>å®ä¾‹ä»£ç </strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">inputs = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">targets = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">inputs = torch.reshape(inputs, (<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>))   <span class="comment"># å˜æˆbatchsizeï¼Œ1é€šé“ï¼Œ1è¡Œ3åˆ—</span></span><br><span class="line">targets = torch.reshape(targets, (<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">loss = nn.L1Loss()</span><br><span class="line">result = loss(inputs, targets)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<h3 id="152-mselosså‡½æ•°">1.5.2 <a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss">MSELoss</a>å‡½æ•°</h3>
<p>è®¡ç®—å¹³æ–¹å·®å‡½æ•°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MSELoss(</span><br><span class="line">    size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>å®ä¾‹ä»£ç </strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">inputs = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">targets = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">inputs = torch.reshape(inputs, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))  <span class="comment"># å˜æˆbatchsizeï¼Œ1é€šé“ï¼Œ1è¡Œ3åˆ—</span></span><br><span class="line">targets = torch.reshape(targets, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">loss_mse = nn.MSELoss()</span><br><span class="line">result_mse = loss_mse(inputs, targets)</span><br><span class="line"><span class="built_in">print</span>(result_mse)</span><br></pre></td></tr></table></figure>

<h3 id="153-crossentropylosså‡½æ•°">1.5.3 <a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss">CrossEntropyLoss</a>å‡½æ•°</h3>
<p>äº¤å‰ç†µå‡½æ•°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CrossEntropyLoss(</span><br><span class="line">    weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, ignore_index=-<span class="number">100</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>, label_smoothing=<span class="number">0.0</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>å®ä¾‹ä»£ç </strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>], dtype=torch.<span class="built_in">float</span>)    <span class="comment"># xæœ‰3ç±»</span></span><br><span class="line">y = torch.tensor([<span class="number">1</span>])</span><br><span class="line">x = torch.reshape(x, (<span class="number">1</span>,<span class="number">3</span>))     <span class="comment"># å˜ä¸º batchsizeï¼Œç±»åˆ«æ•°</span></span><br><span class="line"></span><br><span class="line">loss_cross = nn.CrossEntropyLoss()</span><br><span class="line">result_cross = loss_cross(x, y)</span><br><span class="line"><span class="built_in">print</span>(result_cross)</span><br></pre></td></tr></table></figure>

<h1 id="2-åå‘ä¼ æ’­-backward">2 åå‘ä¼ æ’­ backward</h1>
<p>ä½¿ç”¨ <strong>CrossEntropyLosså‡½æ•°</strong> å®ç°åå‘ä¼ æ’­è®¡ç®—</p>
<p>ç¥ç»ç½‘ç»œä¸­æ¯ä¸ªèŠ‚ç‚¹ï¼ˆè¦æ›´æ–°çš„å‚æ•°ï¼‰éƒ½æœ‰ä¸€ä¸ªæ¢¯åº¦ï¼Œæ ¹æ®æ¢¯åº¦å¯¹å‚æ•°è¿›è¡Œä¼˜åŒ–ï¼Œæœ€ç»ˆå®ç°é™ä½lossçš„ç›®çš„</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TdModule</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TdModule, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.model1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">td = TdModule()</span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    outputs = td(imgs)</span><br><span class="line">    <span class="comment"># print(outputs)      # è¾“å‡ºæœ‰10ä¸ªæ•°å€¼ï¼Œæ¯ä¸€ä¸ªä»£è¡¨æ¯ä¸ªç±»çš„æ¦‚ç‡</span></span><br><span class="line">    <span class="comment"># print(targets)      # å›¾ç‰‡çš„ç±»åˆ«ç¼–å·</span></span><br><span class="line">    result_loss = loss(outputs, targets)    <span class="comment"># äº¤å‰ç†µå‡½æ•°</span></span><br><span class="line">    <span class="built_in">print</span>(result_loss)</span><br><span class="line">    result_loss.backward()     <span class="comment"># å¼€å¯è®¡ç®—æ¢¯åº¦</span></span><br></pre></td></tr></table></figure>

<p><code>.backward()</code>
ç”¨æ¥è®¡ç®—æ¢¯åº¦ï¼Œéœ€è¦ä½¿ç”¨åˆé€‚çš„<strong>ä¼˜åŒ–å™¨</strong>å»æ›´æ–°å‚æ•°ï¼Œä»¥è¾¾åˆ°æ•´ä½“çš„è¯¯å·®é™ä½çš„ç›®çš„</p>
<h1 id="3-ä¼˜åŒ–å™¨-optim"><strong>3 ä¼˜åŒ–å™¨ optim</strong></h1>
<p>pytorchæ–‡æ¡£åœ°å€ï¼š<a
target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/optim.html">https://docs.pytorch.org/docs/stable/optim.html</a></p>
<ul>
<li>params æ¨¡å‹çš„å‚æ•°</li>
<li>lr å­¦ä¹ é€Ÿç‡ learning rate</li>
</ul>
<p><strong>æ„é€ ä¼˜åŒ–å™¨</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"><span class="comment"># optimizer = optim.Adam([var1, var2], lr=0.0001)</span></span><br></pre></td></tr></table></figure>

<p>é¦–å…ˆåœ¨ä¼˜åŒ–å™¨ä¸­æ”¾å…¥æ¨¡å‹çš„å‚æ•°ï¼Œä¼˜åŒ–æ­¥éª¤å¦‚ä¸‹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> dataset:</span><br><span class="line">    optimizer.zero_grad()          <span class="comment"># æ¢¯åº¦æ¸…é›¶</span></span><br><span class="line">    output = model(<span class="built_in">input</span>)          </span><br><span class="line">    loss = loss_fn(output, target) <span class="comment"># è®¡ç®—è¾“å‡ºä¸çœŸå®å€¼çš„è¯¯å·®</span></span><br><span class="line">    loss.backward()                <span class="comment"># å¾—åˆ°æ¯ä¸ªè¦æ›´æ–°å‚æ•°çš„æ¢¯åº¦</span></span><br><span class="line">    optimizer.step()               <span class="comment"># æ¯ä¸ªå‚æ•°éƒ½æ ¹æ®ä¸Šæ­¥çš„æ¢¯åº¦è¿›è¡Œä¼˜åŒ–</span></span><br></pre></td></tr></table></figure>

<p><strong>å®ä¾‹ä»£ç </strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ„å»ºè‡ªå®šä¹‰æ¨¡å‹</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TdModule</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TdModule, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.model1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¼•å…¥æ•°æ®é›†</span></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®ä¾‹åŒ–æ¨¡å‹ï¼Œ.to(&#x27;cuda&#x27;)å°†æ•°æ®ç§»è‡³GPUè®¡ç®—ï¼Œå¦‚æœæ²¡æœ‰GPUï¼Œåˆ™</span></span><br><span class="line">td = TdModule().to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">loss = nn.CrossEntropyLoss().to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨ SGD</span></span><br><span class="line">optim = torch.optim.SGD(td.parameters(), lr=<span class="number">0.01</span>)   <span class="comment"># å®šä¹‰ä¼˜åŒ–å™¨</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        outputs = td(imgs.to(<span class="string">&#x27;cuda&#x27;</span>))</span><br><span class="line">        <span class="comment"># print(outputs)      # è¾“å‡ºæœ‰10ä¸ªæ•°å€¼ï¼Œæ¯ä¸€ä¸ªä»£è¡¨æ¯ä¸ªç±»çš„æ¦‚ç‡</span></span><br><span class="line">        <span class="comment"># print(targets)      # å›¾ç‰‡çš„ç±»åˆ«ç¼–å·</span></span><br><span class="line">        result_loss = loss(outputs, targets.to(<span class="string">&#x27;cuda&#x27;</span>))  <span class="comment"># äº¤å‰ç†µå‡½æ•°</span></span><br><span class="line">        optim.zero_grad()       <span class="comment"># æ¢¯åº¦æ¸…é›¶ï¼Œä¸Šä¸€æ¬¡çš„æ¢¯åº¦å¯¹è¿™ä¸€æ¬¡çš„æ¢¯åº¦æ›´æ–°æ²¡æœ‰ç”¨</span></span><br><span class="line">        result_loss.backward()  <span class="comment"># å¾—åˆ°æ¯ä¸ªå¯ä»¥è°ƒèŠ‚å‚æ•°å¯¹åº”çš„æ¢¯åº¦</span></span><br><span class="line">        optim.step()            <span class="comment"># å¯¹æ¯ä¸ªå‚æ•°è¿›è¡Œè°ƒä¼˜</span></span><br><span class="line">        running_loss = running_loss + result_loss   <span class="comment"># æ•´ä½“è¯¯å·®æ±‚å’Œ</span></span><br><span class="line">    <span class="built_in">print</span>(running_loss)</span><br></pre></td></tr></table></figure>

<h1 id="4-ç°æœ‰ç½‘ç»œæ¨¡å‹">4 ç°æœ‰ç½‘ç»œæ¨¡å‹</h1>
<p>pytorchæ–‡æ¡£åœ°å€ï¼š<a
target="_blank" rel="noopener" href="https://docs.pytorch.org/vision/stable/models.html">https://docs.pytorch.org/vision/stable/models.html</a></p>
<p>torchvisionæ˜¯å…³äº<strong>å›¾åƒ</strong>ç›¸å…³çš„æ¨¡å‹ï¼Œtorchaudioæ˜¯å…³äº<strong>è¯­éŸ³</strong>ç›¸å…³çš„æ¨¡å‹ï¼Œtorchtextæ˜¯å…³äº<strong>æ–‡å­—</strong>ç›¸å…³çš„æ¨¡å‹â€¦</p>
<h2 id="41-vggåˆ†ç±»æ¨¡å‹">4.1 VGGåˆ†ç±»æ¨¡å‹</h2>
<p>å¸¸ç”¨çš„æœ‰VGG16ã€VGG19</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torchvision.models.vgg16(</span><br><span class="line">    *, weights: <span class="type">Optional</span>[VGG16_Weights] = <span class="literal">None</span>, </span><br><span class="line">    progress: <span class="built_in">bool</span> = <span class="literal">True</span>, **kwargs: <span class="type">Any</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>weights</code> (<a
target="_blank" rel="noopener" href="https://docs.pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#torchvision.models.VGG16_Weights">VGG16_Weights</a>,
optional) â€“ ä½¿ç”¨å·²ç»ä¸‹è½½å¥½çš„çš„é¢„è®­ç»ƒæƒé‡ï¼Œå‚é˜… <a
target="_blank" rel="noopener" href="https://docs.pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#torchvision.models.VGG16_Weights">VGG16_Weights</a>
ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä¸ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æƒé‡ã€‚</li>
<li><code>progress</code> (<a
target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,
optional</em>) â€“
å¦‚æœä¸ºTrueï¼Œåˆ™æ˜¾ç¤ºä¸‹è½½åˆ°stderrçš„è¿›åº¦æ¡ã€‚é»˜è®¤å€¼ä¸ºTrueã€‚</li>
<li><code>**kwargs</code> â€“ ä¼ é€’ç»™
<code>torchvision.models.vgg.VGG</code> çš„å‚æ•°ã€‚ æ›´å¤šè¯¦ç»†ä¿¡æ¯å‚é˜… <a
target="_blank" rel="noopener" href="https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py">source
code</a> ã€‚</li>
</ul>
<h2 id="42-æŸ¥çœ‹vggæ¨¡å‹æ¶æ„">4.2 æŸ¥çœ‹VGGæ¨¡å‹æ¶æ„</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"> </span><br><span class="line">vgg16_false = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)    <span class="comment"># ä¸ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹</span></span><br><span class="line">vgg16_true = torchvision.models.vgg16(pretrained=<span class="literal">True</span>)      <span class="comment"># ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹</span></span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(vgg16_true)   <span class="comment"># æŸ¥çœ‹ä¸è®­ç»ƒæ¨¡å‹çš„æ¶æ„</span></span><br></pre></td></tr></table></figure>

<p><strong>VGG æ¨¡å‹æ¶æ„</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">VGG(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">3</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">4</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">5</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">6</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">7</span>): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">8</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">9</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">10</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">11</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">12</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">13</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">14</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">15</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">16</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">17</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">18</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">19</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">20</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">21</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">22</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">23</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">24</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">25</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">26</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">27</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">28</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">29</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">30</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Linear(in_features=<span class="number">25088</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">1</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">3</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">4</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">5</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">6</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="43-ä¿®æ”¹ç½‘ç»œæ¨¡å‹"><strong>4.3 ä¿®æ”¹ç½‘ç»œæ¨¡å‹</strong></h2>
<blockquote>
<p>VGGæ¨¡å‹é€šè¿‡ImageNetæ•°æ®é›†è®­ç»ƒï¼Œæœ€ç»ˆåˆ†ç±»ç±»åˆ«æœ‰1000ä¸ª</p>
<p>CIFAR10æ•°æ®é›†ä¸­åªæœ‰10å„ç±»åˆ«çš„æ•°æ®</p>
<p>å¦‚ä½•åˆ©ç”¨ç°æœ‰çš„ç½‘ç»œï¼Œå»æ”¹åŠ¨å®ƒçš„ç»“æ„</p>
</blockquote>
<p>åœ¨ç½‘ç»œæœ€å<strong>æ·»åŠ ä¸€ä¸ªå±‚çº§</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åœ¨æ¨¡å‹æœ«å°¾æ·»åŠ å±‚çº§</span></span><br><span class="line">vgg16_true.add_module(<span class="string">&#x27;add_linear&#x27;</span>, nn.Linear(<span class="number">1000</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># åœ¨classifieræ¨¡å—æœ€åæ·»åŠ ä¸€ä¸ªå±‚çº§</span></span><br><span class="line">vgg16_true.classifier.add_module(<span class="string">&#x27;add_linear&#x27;</span>, nn.Linear(<span class="number">1000</span>, <span class="number">10</span>))</span><br><span class="line"><span class="built_in">print</span>(vgg16_true)</span><br></pre></td></tr></table></figure>

<p>ä¿®æ”¹æŸä¸ªå±‚çº§å‚æ•°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è°ƒæ•´classifieræ¨¡å—ä¸­ç¬¬6å±‚å‚æ•°</span></span><br><span class="line">vgg16_false.classifier[<span class="number">6</span>] = nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(vgg16_false)</span><br></pre></td></tr></table></figure>

<h1 id="5-æ¨¡å‹ä¿å­˜ä¸åŠ è½½">5 æ¨¡å‹ä¿å­˜ä¸åŠ è½½</h1>
<h2 id="51-ä¿å­˜æ¨¡å‹ç»“æ„å‚æ•°">5.1 ä¿å­˜æ¨¡å‹ç»“æ„(å‚æ•°)</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">vgg16 = torchvision.models.vgg16(weights=<span class="literal">None</span>)      <span class="comment"># åˆå§‹åŒ–æ¨¡å‹</span></span><br></pre></td></tr></table></figure>

<p><strong>ä¿å­˜æ–¹å¼1ï¼Œä¿å­˜æ¨¡å‹ç»“æ„ + æ¨¡å‹å‚æ•°</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(vgg16, <span class="string">&#x27;vgg16_method1.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>ä¿å­˜æ–¹å¼2ï¼ŒæŠŠæ¨¡å‹çš„å‚æ•°ä¿å­˜æˆå­—å…¸ï¼ˆå®˜æ–¹æ¨èï¼‰</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(vgg16.state_dict(), <span class="string">&#x27;vgg16_method2.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="52-æ¨¡å‹åŠ è½½">5.2 æ¨¡å‹åŠ è½½</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>

<p><strong>æ–¹å¼1 â€“&gt; ä¿å­˜æ–¹å¼1ï¼ŒåŠ è½½æ¨¡å‹</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = torch.load(<span class="string">&#x27;vgg16_method1.pth&#x27;</span>, weights_only=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure>

<p><strong>æ–¹å¼2 â€“&gt; ä¿å­˜æ–¹å¼2ï¼ŒåŠ è½½æ¨¡å‹</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vgg16 = torchvision.models.vgg16(weights=<span class="literal">None</span>)</span><br><span class="line">vgg16.load_state_dict(torch.load(<span class="string">&#x27;vgg16_method2.pth&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(vgg16)</span><br><span class="line">                      </span><br><span class="line"><span class="comment"># model = torch.load(&#x27;vgg16_method2.pth&#x27;)   # åŠ è½½æ¨¡å‹æƒé‡ï¼Œè¯»å–å‡ºæ¥å­—å…¸å½¢å¼</span></span><br><span class="line"><span class="comment"># print(model)</span></span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="å¤´åƒ"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/source_fig/avatar1.webp" title="å¤´åƒ" alt="å¤´åƒ"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/source_fig/avatar1.webp" title="å¤´åƒ" alt="å¤´åƒ"></a><div class="post-copyright__author_name">yeximm</div><div class="post-copyright__author_desc">è½è½å†°å·æµè½¬ç€åƒå¹´å¤å¿†</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="è¯¥æ–‡ç« ä¸ºåŸåˆ›æ–‡ç« ï¼Œæ³¨æ„ç‰ˆæƒåè®®" href="https://www.dyeddie.top/20250602/">åŸåˆ›</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('https://www.dyeddie.top/20250602/')">åˆè¯†Pytorch(äºŒ) -- ç¥ç»ç½‘ç»œæ­å»º</span></a></div><div class="post-copyright__notice"><span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="https://www.dyeddie.top" target="_blank">æ«è½ç¹èŠ±</a>ï¼</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/Pytorch/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>Pytorch<span class="tagsPageCount">4</span></a></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>æ–‡ç« ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E9%AA%A8%E6%9E%B6"><span class="toc-text">1 ç¥ç»ç½‘ç»œåŸºæœ¬éª¨æ¶</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E9%AA%A8%E6%9E%B6-containers"><span class="toc-text">1.1 éª¨æ¶ Containers</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#111-module%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-text">1.1.1 Moduleçš„ä½¿ç”¨</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#112-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA-sequential"><span class="toc-text">1.1.2 æ¨¡å‹æ­å»º Sequential</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-%E5%8D%B7%E7%A7%AF%E5%B1%82-convolution-layers"><span class="toc-text">1.2 å·ç§¯å±‚ Convolution Layers</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#121-nnfunctionalconv2d"><span class="toc-text">1.2.1 nn.functional.conv2d</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#122-nnconv2d"><span class="toc-text">1.2.2 nn.Conv2d</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-%E6%B1%A0%E5%8C%96%E5%B1%82-pooling-layers"><span class="toc-text">1.3 æ± åŒ–å±‚ Pooling layers</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#131-nnmaxpool2d"><span class="toc-text">1.3.1 nn.MaxPool2d</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#132-%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96%E4%BD%9C%E7%94%A8"><span class="toc-text">1.3.2 æœ€å¤§æ± åŒ–ä½œç”¨</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB-non-linear-activations"><span class="toc-text">1.4 éçº¿æ€§æ¿€æ´» Non-linear
Activations</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#141-relu%E5%87%BD%E6%95%B0"><span class="toc-text">1.4.1 ReLUå‡½æ•°</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#142-sigmoid%E5%87%BD%E6%95%B0"><span class="toc-text">1.4.2 Sigmoidå‡½æ•°</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-loss-functions"><span class="toc-text">1.5 æŸå¤±å‡½æ•° Loss Functions</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#151-l1loss%E5%87%BD%E6%95%B0"><span class="toc-text">1.5.1 L1Losså‡½æ•°</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#152-mseloss%E5%87%BD%E6%95%B0"><span class="toc-text">1.5.2 MSELosså‡½æ•°</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#153-crossentropyloss%E5%87%BD%E6%95%B0"><span class="toc-text">1.5.3 CrossEntropyLosså‡½æ•°</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-backward"><span class="toc-text">2 åå‘ä¼ æ’­ backward</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E4%BC%98%E5%8C%96%E5%99%A8-optim"><span class="toc-text">3 ä¼˜åŒ–å™¨ optim</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E7%8E%B0%E6%9C%89%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B"><span class="toc-text">4 ç°æœ‰ç½‘ç»œæ¨¡å‹</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#41-vgg%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="toc-text">4.1 VGGåˆ†ç±»æ¨¡å‹</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#42-%E6%9F%A5%E7%9C%8Bvgg%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84"><span class="toc-text">4.2 æŸ¥çœ‹VGGæ¨¡å‹æ¶æ„</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#43-%E4%BF%AE%E6%94%B9%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B"><span class="toc-text">4.3 ä¿®æ”¹ç½‘ç»œæ¨¡å‹</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD"><span class="toc-text">5 æ¨¡å‹ä¿å­˜ä¸åŠ è½½</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#51-%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E5%8F%82%E6%95%B0"><span class="toc-text">5.1 ä¿å­˜æ¨¡å‹ç»“æ„(å‚æ•°)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#52-%E6%A8%A1%E5%9E%8B%E5%8A%A0%E8%BD%BD"><span class="toc-text">5.2 æ¨¡å‹åŠ è½½</span></a></li></ol></li></ol></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="åšå®¢æ¡†æ¶ä¸ºHexo-cli-v4.3.2" title="åšå®¢æ¡†æ¶ä¸ºHexo-cli-v4.3.2"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/source_fig/bottom_footer/Frame-Hexo.svg" alt="åšå®¢æ¡†æ¶ä¸ºHexo-cli-v4.3.2"/></a><a class="github-badge" target="_blank" href="https://hexo.anheyu.com/" style="margin-inline:5px" data-title="æœ¬ç«™ä½¿ç”¨AnZhiYuä¸»é¢˜" title="æœ¬ç«™ä½¿ç”¨AnZhiYuä¸»é¢˜"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/source_fig/bottom_footer/Theme-AnZhiYu-2E67D3.svg" alt="æœ¬ç«™ä½¿ç”¨AnZhiYuä¸»é¢˜"/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="æœ¬ç«™é¡¹ç›®ç”±Githubæ‰˜ç®¡" title="æœ¬ç«™é¡¹ç›®ç”±Githubæ‰˜ç®¡"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/source_fig/bottom_footer/Source-Github.svg" alt="æœ¬ç«™é¡¹ç›®ç”±Githubæ‰˜ç®¡"/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="æœ¬ç«™é‡‡ç”¨çŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº«4.0å›½é™…è®¸å¯åè®®è¿›è¡Œè®¸å¯" title="æœ¬ç«™é‡‡ç”¨çŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº«4.0å›½é™…è®¸å¯åè®®è¿›è¡Œè®¸å¯"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/source_fig/bottom_footer/Copyright-BY-NC-SA.svg" alt="æœ¬ç«™é‡‡ç”¨çŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº«4.0å›½é™…è®¸å¯åè®®è¿›è¡Œè®¸å¯"/></a></p></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2024 - 2025 By <a class="footer-bar-link" href="/" title="yeximm" target="_blank">yeximm</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" title="å†€ICPå¤‡2024076436å·">å†€ICPå¤‡2024076436å·</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">æ–‡ç« </div><div class="length-num">18</div></a><a href="/tags/" title="tag"><div class="headline">æ ‡ç­¾</div><div class="length-num">12</div></a><a href="/categories/" title="category"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><span class="sidebar-menu-item-title">åŠŸèƒ½</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="æ˜¾ç¤ºæ¨¡å¼"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>æ˜¾ç¤ºæ¨¡å¼</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">å…¶ä»–</div><div class="back-menu-list"><a class="back-menu-item" href="/archives/" title="æ–‡ç« å½’æ¡£"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/source_fig/archieves.jpg" alt="æ–‡ç« å½’æ¡£"/><span class="back-menu-item-text">æ–‡ç« å½’æ¡£</span></a><a class="back-menu-item" href="/music/?id=9499657499&amp;server=tencent" title="å¬åŠ›ç»ƒä¹ "><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/source_fig/de36c853a5ea9.jpg" alt="å¬åŠ›ç»ƒä¹ "/><span class="back-menu-item-text">å¬åŠ›ç»ƒä¹ </span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">é¡¹ç›®</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="å®‰çŸ¥é±¼å›¾åºŠ"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://image.anheyu.com/favicon.ico" alt="å®‰çŸ¥é±¼å›¾åºŠ"/><span class="back-menu-item-text">å®‰çŸ¥é±¼å›¾åºŠ</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> æ–‡ç« </span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="fa-solid fa-layer-group faa-tada"></i><span> ç±»åˆ«</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="fa-solid fa-tag faa-tada"></i><span> æ ‡ç­¾</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> è§£å‹</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/apps/"><i class="fa-solid fa-icons faa-tada"></i><span> ä¿®ä»™å®¤</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> æˆ‘çš„</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="fa-solid fa-eject faa-tada"></i><span> å…³äº</span></a></li></ul></div></div><span class="sidebar-menu-item-title">æ ‡ç­¾</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/ArchLinux/" style="font-size: 0.88rem; color: rgb(186, 53, 107);">ArchLinux<sup>1</sup></a><a href="/tags/GitHub/" style="font-size: 0.88rem; color: rgb(139, 27, 11);">GitHub<sup>2</sup></a><a href="/tags/Linux/" style="font-size: 0.88rem; color: rgb(144, 92, 50);">Linux<sup>5</sup></a><a href="/tags/Numpy/" style="font-size: 0.88rem; color: rgb(156, 186, 96);">Numpy<sup>1</sup></a><a href="/tags/Oral-Practice/" style="font-size: 0.88rem; color: rgb(200, 200, 52);">Oral_Practice<sup>2</sup></a><a href="/tags/Python/" style="font-size: 0.88rem; color: rgb(63, 113, 122);">Python<sup>1</sup></a><a href="/tags/Pytorch/" style="font-size: 0.88rem; color: rgb(62, 109, 158);">Pytorch<sup>4</sup></a><a href="/tags/Skills/" style="font-size: 0.88rem; color: rgb(142, 176, 184);">Skills<sup>1</sup></a><a href="/tags/Sublime-Text/" style="font-size: 0.88rem; color: rgb(111, 37, 31);">Sublime_Text<sup>1</sup></a><a href="/tags/Ubuntu/" style="font-size: 0.88rem; color: rgb(24, 144, 46);">Ubuntu<sup>2</sup></a><a href="/tags/Xfce/" style="font-size: 0.88rem; color: rgb(160, 0, 122);">Xfce<sup>1</sup></a><a href="/tags/conda%E5%91%BD%E4%BB%A4/" style="font-size: 0.88rem; color: rgb(131, 165, 82);">condaå‘½ä»¤<sup>1</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="ç®€ç¹è½¬æ¢">ç¹</button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>å¤åˆ¶é€‰ä¸­æ–‡æœ¬</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>ç²˜è´´æ–‡æœ¬</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>å¼•ç”¨åˆ°è¯„è®º</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>æ–°çª—å£æ‰“å¼€</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>å¤åˆ¶é“¾æ¥åœ°å€</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>å¤åˆ¶æ­¤å›¾ç‰‡</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>ä¸‹è½½æ­¤å›¾ç‰‡</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>æ–°çª—å£æ‰“å¼€å›¾ç‰‡</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>ç«™å†…æœç´¢</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>ç™¾åº¦æœç´¢</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>æ’­æ”¾éŸ³ä¹</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>åˆ‡æ¢åˆ°ä¸Šä¸€é¦–</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>åˆ‡æ¢åˆ°ä¸‹ä¸€é¦–</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/1529755364&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>æŸ¥çœ‹æ‰€æœ‰æ­Œæ›²</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>å¤åˆ¶æ­Œå</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>éšä¾¿é€›é€›</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>åšå®¢åˆ†ç±»</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>æ–‡ç« æ ‡ç­¾</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>å¤åˆ¶åœ°å€</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">å…³é—­çƒ­è¯„</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">æ·±è‰²æ¨¡å¼</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>è½‰ç‚ºç¹é«”</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@6.1.6/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@19.1.3/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script async src="/anzhiyu/random.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><input type="hidden" name="page-type" id="page-type" value="post"></div><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://cdn.cbd.int/qrcodejs@1.0.0/qrcode.min.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: true,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', 'G-3RZJMX45BS', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script></div><div id="popup-window"><div class="popup-window-title">é€šçŸ¥</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">ä½ å¥½å‘€</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>