<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>初识Pytorch(三) -- 完整的模型训练流程 + GPU调用训练 | 枫落繁花</title><meta name="keywords" content="Pytorch,Python,Deep Learning"><meta name="author" content="山河忽晚"><meta name="copyright" content="山河忽晚"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="初识Pytorch(三) -- 完整的模型训练流程 + GPU调用训练"><meta name="application-name" content="初识Pytorch(三) -- 完整的模型训练流程 + GPU调用训练"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="初识Pytorch(三) -- 完整的模型训练流程 + GPU调用训练"><meta property="og:url" content="https://www.dyeddie.top/20250603/index.html"><meta property="og:site_name" content="枫落繁花"><meta property="og:description" content="1 构建训练模型以CIFAR10数据集为例 1.1 导入torch模块123import torchvisionfrom torch import nnfrom torch.utils.data import DataLoader  1.2 准备数据集12345678910# 准备数据集train_"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.dyeddie.top/20250603/105204nCGuS.jpg"><meta property="article:author" content="山河忽晚"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://www.dyeddie.top/20250603/105204nCGuS.jpg"><meta name="description" content="1 构建训练模型以CIFAR10数据集为例 1.1 导入torch模块123import torchvisionfrom torch import nnfrom torch.utils.data import DataLoader  1.2 准备数据集12345678910# 准备数据集train_"><link rel="shortcut icon" href="/ye_source/favicon.png"><link rel="canonical" href="https://www.dyeddie.top/20250603/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//static.cloudflareinsights.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="codeva-5ZQ1tY7sUA"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?34e134fb3c7108fe3f44bc4e6f57c1f8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-3RZJMX45BS"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-3RZJMX45BS');
</script><script defer="defer" data-pjax="data-pjax" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;38de068f639745a0a8b37427ef001545&quot;}"></script><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: {"enable":true,"img":"https://upload-bbs.miyoushe.com/upload/2023/09/03/125766904/ee23df8517f3c3e3efc4145658269c06_5714860933110284659.png"},
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: undefined,
  LA51: undefined,
  greetingBox: undefined,
  twikooEnvId: '',
  commentBarrageConfig:undefined,
  root: '/',
  preloader: {"source":1},
  friends_vue_info: undefined,
  navMusic: false,
  mainTone: {"mode":"api","api":null,"cover_change":true},
  authorStatus: undefined,
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    simplehomepage: false,
    post: true
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: 山河忽晚","link":"链接: ","source":"来源: 枫落繁花","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '枫落繁花',
  title: '初识Pytorch(三) -- 完整的模型训练流程 + GPU调用训练',
  postAI: '',
  pageFillDescription: '1 构建训练模型, 1.1 导入torch模块, 1.2 准备数据集, 1.3 查看数据集的大小, 1.4 加载数据集, 1.5 搭建模型, 1.6 训练参数设置, 1.7 模型训练与测试, 1.8 正确率(分类问题), 1.9 完整代码, 2 使用 GPU 训练, 2.1 调用方式 1, 2.2 调用方式 2, 3 测试模型结果构建训练模型以数据集为例导入模块准备数据集准备数据集查看数据集的大小长度训练数据集的长度为测试数据集的长度为加载数据集利用加载数据集搭建模型以的结构为例神经网络模型结构如下创建文件存放自定义模型文件训练参数设置创建网络模型损失函数优化器学习率学习率设置训练网络的一些参数记录训练的次数记录测试的次数训练的轮次模型训练与测试使用记录训练过程查看模型是否训练达到自己的需求每次训练完一轮后在测试数据集上跑一遍用测试数据集的损失或正确率来评估模型有没有训练好添加训练内容第轮训练开始训练步骤开始损失值优化器模型梯度清零计算每个权重的梯度进行权重优化训练次数统计训练步骤逢百打印训练次数测试步骤开始禁用梯度计算不去梯度使用已训练的模型进行推理为数据类型为普通数字类型整体测试集上的模型已保存正确率分类问题即便得到整体数据集上的也不能很好地说明模型在测试集上的效果在分类问题中可以用正确率来表示模型是否优秀对于目标检测语义分割等操作可以直接把得到的输出在中显示正确率测试说明自定义三种类别两个样本一行为一个样本的数据水平方向对每一行操作返回该行中最大值的索引垂直方向对每一列操作返回该列中最大值的索引样本验证找到每个样本中概率最大的索引只有两个样本样本的标签对应只有两个计算对应位置相等的个数将代码优化模型训练与测试计算测试集中整体的正确个数测试步骤开始计算测试集上的正确率整体测试集上的正确率整体测试集上的保存每轮训练的结果第次训练模型已保存完整代码准备数据集数据集长度训练数据集的长度为测试数据集的长度为准备加载数据集创建网络模型网络模型在文件中损失函数优化器学习率学习率设置训练网络的一些参数记录训练的次数记录测试的次数训练的轮次添加开始训练内容以每个为一轮回实现多次训练第轮训练开始训练步骤开始模型网络进入训练状态这仅对某些模块有效例如等从训练的中不断的取数据计算损失值优化器模型计算出误差后放入优化器中进行优化梯度清零计算每个权重的梯度进行权重优化展示输出训练次数统计训练次数测试步骤开始在一轮结束或特定步数后进行测试这仅对某些模块有效例如等禁用梯度计算不去梯度计算测试集上的正确率整体测试集上的正确率整体测试集上的保存每轮训练的结果第次训练模型已保存使用训练调用方式只有网络模型损失函数数据输入输出可以设置为运算使用方式在对象后添加网络模型创建网络模型网络模型在文件中损失函数损失函数输入输出数据训练步骤开始模型网络进入训练状态这仅对某些模块有效例如等从训练的中不断的取数据计算损失值调用方式使用方式在对象后添加指定运算设备为指定运算设备为默认为第一张显卡指定运算设备为使用第一张显卡指定运算设备为使用第二张显卡指定设备指定训练的设备调用设备创建网络模型网络模型在文件中损失函数从训练的中取数据测试模型结果利用已经训练好的模型给模型提供输入从网络上下载一个图片使用读取图片因为格式是四个通道除了三通道外还有一个透明度通道调用保留图片的颜色通道如果图片本来就是三个颜色通道经过此操作后无变化加上这一步后可以适应等格式的图片使用读取图片调整图像大小联立对输入图像进行尺寸调整加载网络模型加载网络模型注意此时引用的模型文件是用训练的如果测试时使用的是则需要指定设备到去运算输入图片推理结果用于将模型设置为评估模式禁用梯度计算节省内存加速推理',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-06-23 13:18:02',
  postMainColor: '#716557',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="/ye_source/avatar1.webp"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><a id="site-name" href="/" accesskey="h"><div class="title">枫落繁花</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 类别</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 解压</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/?id=3778678&amp;server=netease"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/apps/"><i class="fa-brands fa-canadian-maple-leaf faa-tada"></i><span> 修仙室</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> About</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" alt="微信" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/ArchLinux/" style="font-size: 1.05rem; color: rgb(88, 144, 21);">ArchLinux<sup>1</sup></a><a href="/tags/GitHub/" style="font-size: 1.05rem; color: rgb(10, 135, 189);">GitHub<sup>2</sup></a><a href="/tags/Linux/" style="font-size: 1.05rem; color: rgb(101, 37, 149);">Linux<sup>5</sup></a><a href="/tags/Numpy/" style="font-size: 1.05rem; color: rgb(5, 27, 111);">Numpy<sup>1</sup></a><a href="/tags/Oral-Practice/" style="font-size: 1.05rem; color: rgb(113, 139, 15);">Oral_Practice<sup>2</sup></a><a href="/tags/Python/" style="font-size: 1.05rem; color: rgb(172, 82, 175);">Python<sup>1</sup></a><a href="/tags/Pytorch/" style="font-size: 1.05rem; color: rgb(93, 115, 159);">Pytorch<sup>4</sup></a><a href="/tags/Skills/" style="font-size: 1.05rem; color: rgb(102, 151, 133);">Skills<sup>1</sup></a><a href="/tags/Sublime-Text/" style="font-size: 1.05rem; color: rgb(194, 136, 74);">Sublime_Text<sup>1</sup></a><a href="/tags/Ubuntu/" style="font-size: 1.05rem; color: rgb(155, 112, 159);">Ubuntu<sup>2</sup></a><a href="/tags/Xfce/" style="font-size: 1.05rem; color: rgb(154, 12, 49);">Xfce<sup>1</sup></a><a href="/tags/conda%E5%91%BD%E4%BB%A4/" style="font-size: 1.05rem; color: rgb(57, 54, 75);">conda命令<sup>1</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/06/"><span class="card-archive-list-date">六月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">4</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">8</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url">深度学习</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/Pytorch/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>Pytorch</span></a></span></div></div><h1 class="post-title" itemprop="name headline">初识Pytorch(三) -- 完整的模型训练流程 + GPU调用训练</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="post-meta-icon anzhiyufont anzhiyu-icon-history"></i><span class="post-meta-label">更新于</span><time itemprop="dateCreated datePublished" datetime="2025-06-23T05:18:02.897Z" title="更新于 2025-06-23 13:18:02">2025-06-23</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">2.4k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>10分钟</span></span><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="初识Pytorch(三) -- 完整的模型训练流程 + GPU调用训练"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://www.dyeddie.top/20250603/105204nCGuS.jpg"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="https://www.dyeddie.top/20250603/"><header><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url">深度学习</a><a href="/tags/Pytorch/" tabindex="-1" itemprop="url">Pytorch</a><h1 id="CrawlerTitle" itemprop="name headline">初识Pytorch(三) -- 完整的模型训练流程 + GPU调用训练</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">山河忽晚</span><time itemprop="dateCreated datePublished" datetime="2025-06-23T05:18:02.897Z" title="undefined 2025-06-23 13:18:02">2025-06-23</time></header><h1 id="1-构建训练模型"><a href="#1-构建训练模型" class="headerlink" title="1 构建训练模型"></a>1 构建训练模型</h1><p>以CIFAR10数据集为例</p>
<h2 id="1-1-导入torch模块"><a href="#1-1-导入torch模块" class="headerlink" title="1.1 导入torch模块"></a>1.1 导入torch模块</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br></pre></td></tr></table></figure>

<h2 id="1-2-准备数据集"><a href="#1-2-准备数据集" class="headerlink" title="1.2 准备数据集"></a>1.2 准备数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 准备数据集</span></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(</span><br><span class="line">    root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">    transform=torchvision.transforms.ToTensor()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_data = torchvision.datasets.CIFAR10(</span><br><span class="line">    root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">    transform=torchvision.transforms.ToTensor()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="1-3-查看数据集的大小"><a href="#1-3-查看数据集的大小" class="headerlink" title="1.3 查看数据集的大小"></a>1.3 查看数据集的大小</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># length 长度</span></span><br><span class="line">train_data_size = <span class="built_in">len</span>(train_data)</span><br><span class="line">test_data_size = <span class="built_in">len</span>(test_data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练数据集的长度为：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(train_data_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据集的长度为：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(test_data_size))</span><br></pre></td></tr></table></figure>

<h2 id="1-4-加载数据集"><a href="#1-4-加载数据集" class="headerlink" title="1.4 加载数据集"></a>1.4 加载数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用dataloader加载数据集</span></span><br><span class="line">train_dataloader = DataLoader(train_data, batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=<span class="number">64</span>)</span><br></pre></td></tr></table></figure>

<h2 id="1-5-搭建模型"><a href="#1-5-搭建模型" class="headerlink" title="1.5 搭建模型"></a>1.5 搭建模型</h2><p>以 CIFAR 10 的结构为例，神经网络模型结构如下</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/./20250603/image-20250604122341166.png" alt="image-20250604122341166"></p>
<p>创建model.py文件存放自定义模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model.py文件</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TdModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TdModel, self).__init__()</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">64</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.model(x)</span><br></pre></td></tr></table></figure>

<h2 id="1-6-训练参数设置"><a href="#1-6-训练参数设置" class="headerlink" title="1.6 训练参数设置"></a>1.6 训练参数设置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建网络模型</span></span><br><span class="line">td = TdModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line">lose_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化器</span></span><br><span class="line"><span class="comment"># learning_rate = 0.01    # 学习率</span></span><br><span class="line"><span class="comment"># 1e-2 = 1*(10)^(-2) = 1/100 = 0.01</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span>    <span class="comment"># 学习率</span></span><br><span class="line">optimizer = torch.optim.SGD(td.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练网络的一些参数</span></span><br><span class="line"><span class="comment"># 记录训练的次数</span></span><br><span class="line">total_train_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 记录测试的次数</span></span><br><span class="line">total_test_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 训练的轮次</span></span><br><span class="line">epoch = <span class="number">10</span></span><br></pre></td></tr></table></figure>

<h2 id="1-7-模型训练与测试"><a href="#1-7-模型训练与测试" class="headerlink" title="1.7 模型训练与测试"></a>1.7 模型训练与测试</h2><p>使用<strong>tensorboard</strong>记录训练过程，查看模型是否训练达到自己的需求：</p>
<p>每次训练完一轮后，在测试数据集上跑一遍，用测试数据集的<strong>损失或正确率</strong>来评估模型有没有训练好。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加tensorboard</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;logs&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练内容</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;--------------------第&#123;&#125;轮训练开始--------------------&#x27;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 训练步骤开始</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        outputs = td(imgs)</span><br><span class="line">        loss = lose_fn(outputs, targets)    <span class="comment"># 损失值</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 优化器模型</span></span><br><span class="line">        optimizer.zero_grad()               <span class="comment"># 梯度清零</span></span><br><span class="line">        loss.backward()                     <span class="comment"># 计算每个权重的梯度</span></span><br><span class="line">        optimizer.step()                    <span class="comment"># 进行权重优化</span></span><br><span class="line">        </span><br><span class="line">        total_train_step += <span class="number">1</span>               <span class="comment"># 训练次数统计</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step % <span class="number">100</span> == <span class="number">0</span>:     <span class="comment"># 训练步骤逢百打印</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;训练次数：&#123;0&#125;，Loss：&#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(total_train_step, loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;train_loss&#x27;</span>, loss.item(), total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试步骤开始</span></span><br><span class="line">    total_test_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():    <span class="comment"># 禁用梯度计算，不去track梯度</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs, targets = data</span><br><span class="line">            outputs = td(imgs)        <span class="comment"># 使用已训练的模型进行推理</span></span><br><span class="line">            loss = lose_fn(outputs, targets)</span><br><span class="line">            total_test_loss += loss.item()    <span class="comment"># loss为tensor数据类型，loss.item()为普通数字类型</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;整体测试集上的Loss：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(total_test_loss))</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;test_loss&#x27;</span>, total_test_loss, total_test_step, )</span><br><span class="line">        total_test_step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        torch.save(td, <span class="string">&#x27;./td_model&#123;&#125;.pt&#x27;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;模型已保存&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="1-8-正确率-分类问题"><a href="#1-8-正确率-分类问题" class="headerlink" title="1.8 正确率(分类问题)"></a>1.8 正确率(分类问题)</h2><p>即便得到整体数据集上的Loss，也不能很好地说明模型在测试集上的效果</p>
<p>在分类问题中可以用<strong>正确率</strong>来表示模型是否优秀</p>
<p>对于目标检测、语义分割等操作，可以直接把得到的输出在tensorboard中显示</p>
<p><strong>正确率测试说明</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">outputs = torch.tensor(         <span class="comment"># 自定义三种类别，两个样本（一行为一个样本的数据）</span></span><br><span class="line">    [[<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.8</span>],</span><br><span class="line">     [<span class="number">0.5</span>,<span class="number">0.05</span>,<span class="number">0.4</span>]]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(outputs.argmax(<span class="number">0</span>))    <span class="comment"># tensor([1, 0, 0])</span></span><br><span class="line"><span class="built_in">print</span>(outputs.argmax(<span class="number">1</span>))    <span class="comment"># tensor([2, 0])</span></span><br><span class="line"><span class="comment"># argmax(1)水平方向，对每一行操作，返回该行中最大值的索引</span></span><br><span class="line"><span class="comment"># argmax(0) 垂直方向，对每一列操作，返回该列中最大值的索引</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本验证</span></span><br><span class="line">preds = outputs.argmax(<span class="number">1</span>)           <span class="comment"># 找到每个样本中概率最大的索引</span></span><br><span class="line">targets = torch.tensor([<span class="number">2</span>,<span class="number">1</span>])       <span class="comment"># 只有两个样本，样本的标签对应只有两个！！！</span></span><br><span class="line">true_number = (preds == targets)    <span class="comment"># tensor([ True, False])</span></span><br><span class="line"><span class="built_in">print</span>(true_number.<span class="built_in">sum</span>())            <span class="comment"># 计算对应位置相等的个数</span></span><br><span class="line"><span class="comment"># tensor(1)</span></span><br></pre></td></tr></table></figure>

<p>将**[1.7代码优化](#1.7 模型训练与测试)**，计算测试集中整体的正确个数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 测试步骤开始</span><br><span class="line">total_test_loss = 0</span><br><span class="line">total_test_accuracy = 0</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    for data in test_dataloader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        outputs = td(imgs)</span><br><span class="line">        loss = lose_fn(outputs, targets)</span><br><span class="line">        total_test_loss += loss.item()</span><br><span class="line">        </span><br><span class="line">    # 计算测试集上的正确率    </span><br><span class="line">        accuracy = (outputs.argmax(dim=1) == targets).sum()</span><br><span class="line">        total_test_accuracy += accuracy.item()</span><br><span class="line">    print(&#x27;整体测试集上的正确率：&#123;&#125;&#x27;.format(total_test_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(&#x27;test_accuracy&#x27;, total_test_accuracy/test_data_size, total_test_step)</span><br><span class="line">        </span><br><span class="line">    print(&#x27;整体测试集上的Loss：&#123;&#125;&#x27;.format(total_test_loss))</span><br><span class="line">    writer.add_scalar(&#x27;test_loss&#x27;, total_test_loss, total_test_step, )</span><br><span class="line">    total_test_step += 1</span><br><span class="line">    </span><br><span class="line">    # 保存每轮训练的结果</span><br><span class="line">    torch.save(td, &#x27;./td_model_&#123;&#125;.pth&#x27;.format(i))</span><br><span class="line">    print(&#x27;第&#123;&#125;次训练模型已保存&#x27;.format(i))</span><br></pre></td></tr></table></figure>

<h2 id="1-9-完整代码"><a href="#1-9-完整代码" class="headerlink" title="1.9 完整代码"></a>1.9 完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.准备数据集</span></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(</span><br><span class="line">    root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">    transform=torchvision.transforms.ToTensor()</span><br><span class="line">)</span><br><span class="line">test_data = torchvision.datasets.CIFAR10(</span><br><span class="line">    root=<span class="string">&#x27;./dataset&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">    transform=torchvision.transforms.ToTensor()</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 数据集 length 长度</span></span><br><span class="line">train_data_size = <span class="built_in">len</span>(train_data)</span><br><span class="line">test_data_size = <span class="built_in">len</span>(test_data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练数据集的长度为：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(train_data_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据集的长度为：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(test_data_size))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.准备dataloader加载数据集</span></span><br><span class="line">train_dataloader = DataLoader(train_data, batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.创建网络模型</span></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> *    <span class="comment"># 网络模型TdModel()在model.py文件中</span></span><br><span class="line">td = TdModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.损失函数</span></span><br><span class="line">lose_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.优化器</span></span><br><span class="line"><span class="comment"># learning_rate = 0.01    # 学习率</span></span><br><span class="line"><span class="comment"># 1e-2 = 1*(10)^(-2) = 1/100 = 0.01</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span>    <span class="comment"># 学习率</span></span><br><span class="line">optimizer = torch.optim.SGD(td.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.设置训练网络的一些参数</span></span><br><span class="line">total_train_step = <span class="number">0</span>    <span class="comment"># 记录训练的次数</span></span><br><span class="line">total_test_step = <span class="number">0</span>     <span class="comment"># 记录测试的次数</span></span><br><span class="line">epoch = <span class="number">50</span>              <span class="comment"># 训练的轮次 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加tensorboard</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./logs&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7.开始训练内容，以每个epoch为一轮回，实现多次训练</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;--------------------第&#123;&#125;轮训练开始--------------------&#x27;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 8.训练步骤开始，模型网络进入训练状态</span></span><br><span class="line">    <span class="comment"># td.train()    # 这仅对某些模块有效，例如 Dropout、BatchNorm 等</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:    <span class="comment"># 从训练的dataloader中不断的取数据</span></span><br><span class="line">        imgs, targets = data</span><br><span class="line">        outputs = td(imgs)</span><br><span class="line">        loss = lose_fn(outputs, targets)    <span class="comment"># 计算损失值</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 9.优化器模型，计算出误差后放入优化器中进行优化</span></span><br><span class="line">        optimizer.zero_grad()               <span class="comment"># 梯度清零</span></span><br><span class="line">        loss.backward()                     <span class="comment"># 计算每个权重的梯度</span></span><br><span class="line">        optimizer.step()                    <span class="comment"># 进行权重优化</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 10.展示输出</span></span><br><span class="line">        total_train_step += <span class="number">1</span>               <span class="comment"># 训练次数统计</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;训练次数：&#123;0&#125;，Loss：&#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(total_train_step, loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;train_loss&#x27;</span>, loss.item(), total_train_step)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 11.测试步骤开始，在 一轮结束 或 特定步数 后进行测试</span></span><br><span class="line">    <span class="comment"># td.eval()    # 这仅对某些模块有效。例如 Dropout、BatchNorm 等</span></span><br><span class="line">    total_test_loss = <span class="number">0</span></span><br><span class="line">    total_test_accuracy = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():          <span class="comment"># 禁用梯度计算，不去track梯度</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs, targets = data</span><br><span class="line">            outputs = td(imgs)</span><br><span class="line">            loss = lose_fn(outputs, targets)</span><br><span class="line">            total_test_loss += loss.item()</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 计算测试集上的正确率    </span></span><br><span class="line">            accuracy = (outputs.argmax(dim=<span class="number">1</span>) == targets).<span class="built_in">sum</span>()</span><br><span class="line">            total_test_accuracy += accuracy.item()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;整体测试集上的正确率：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(total_test_accuracy/test_data_size))</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;test_accuracy&#x27;</span>, total_test_accuracy/test_data_size, total_test_step)</span><br><span class="line">            </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;整体测试集上的Loss：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(total_test_loss))</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;test_loss&#x27;</span>, total_test_loss, total_test_step, )</span><br><span class="line">        total_test_step += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存每轮训练的结果</span></span><br><span class="line">        torch.save(td, <span class="string">&#x27;./td_model_&#123;&#125;.pth&#x27;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;第&#123;&#125;次训练模型已保存&#x27;</span>.<span class="built_in">format</span>(i))</span><br></pre></td></tr></table></figure>

<h1 id="2-使用-GPU-训练"><a href="#2-使用-GPU-训练" class="headerlink" title="2 使用 GPU 训练"></a>2 使用 GPU 训练</h1><h2 id="2-1-调用方式-1"><a href="#2-1-调用方式-1" class="headerlink" title="2.1 调用方式 1"></a>2.1 调用方式 1</h2><p>只有<strong>网络模型</strong>、<strong>损失函数</strong>、<strong>数据（输入、输出）</strong>可以设置为GPU运算</p>
<p>使用方式：在对象后添加 <strong>.cuda()</strong></p>
<p><strong>网络模型</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3.创建网络模型</span></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> *    <span class="comment"># 网络模型TdModel()在model.py文件中</span></span><br><span class="line">td = TdModel()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    td = td.cuda()</span><br></pre></td></tr></table></figure>

<p><strong>损失函数</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4.损失函数</span></span><br><span class="line">lose_fn = nn.CrossEntropyLoss()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    lose_fn = lose_fn.cuda()</span><br></pre></td></tr></table></figure>

<p><strong>输入、输出数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 8.训练步骤开始，模型网络进入训练状态</span></span><br><span class="line"><span class="comment"># td.train()    # 这仅对某些模块有效，例如 Dropout、BatchNorm 等</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:    <span class="comment"># 从训练的dataloader中不断的取数据</span></span><br><span class="line">    imgs, targets = data</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        imgs, targets = imgs.cuda(), targets.cuda()</span><br><span class="line">    outputs = td(imgs)</span><br><span class="line">    loss = lose_fn(outputs, targets)    <span class="comment"># 计算损失值</span></span><br></pre></td></tr></table></figure>

<h2 id="2-2-调用方式-2"><a href="#2-2-调用方式-2" class="headerlink" title="2.2 调用方式 2"></a>2.2 调用方式 2</h2><p>使用方式：在对象后添加 <code>.to(device)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cpu&#x27;</span>)    <span class="comment"># 指定运算设备为cpu</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)      <span class="comment"># 指定运算设备为gpu，默认为第一张显卡</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)    <span class="comment"># 指定运算设备为gpu，使用第一张显卡</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:1&#x27;</span>)    <span class="comment"># 指定运算设备为gpu，使用第二张显卡</span></span><br></pre></td></tr></table></figure>

<p><strong>指定设备</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定训练的设备</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>调用设备</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3.创建网络模型</span></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> *    <span class="comment"># 网络模型TdModel()在model.py文件中</span></span><br><span class="line">td = TdModel()</span><br><span class="line">td = td.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.损失函数</span></span><br><span class="line">lose_fn = nn.CrossEntropyLoss()</span><br><span class="line">lose_fn = lose_fn.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从训练的dataloader中取数据</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:    </span><br><span class="line">    imgs, targets = data</span><br><span class="line">    imgs, targets = imgs.to(device), targets.to(device)</span><br></pre></td></tr></table></figure>

<h1 id="3-测试模型结果"><a href="#3-测试模型结果" class="headerlink" title="3 测试模型结果"></a>3 测试模型结果</h1><p>利用已经训练好的模型，给模型提供输入</p>
<p>从网络上下载一个图片，使用PIL读取图片</p>
<blockquote>
<p>因为png格式是四个通道，除了RGB三通道外，还有一个透明度通道</p>
<p>调用 image &#x3D; image.convert(‘RGB’) 保留图片的颜色通道</p>
<p>如果图片本来就是三个颜色通道，经过此操作后，无变化</p>
<p>加上这一步后可以适应png、jpg等格式的图片</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用PIL读取图片</span></span><br><span class="line">image_path = <span class="string">&#x27;images/dog.png&#x27;</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(image_path)  </span><br><span class="line">image = image.convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(image)</span><br><span class="line"><span class="comment"># &lt;PIL.Image.Image image mode=RGB size=197x143 at 0x1991212BE20&gt;</span></span><br></pre></td></tr></table></figure>

<p>调整图像大小</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">transform = torchvision.transforms.Compose([    <span class="comment"># 联立transform</span></span><br><span class="line">    torchvision.transforms.Resize((<span class="number">32</span>,<span class="number">32</span>)),     <span class="comment"># 对输入图像进行尺寸调整。</span></span><br><span class="line">    torchvision.transforms.ToTensor(),</span><br><span class="line">])</span><br><span class="line">image = transform(image)</span><br><span class="line"><span class="built_in">print</span>(image.shape)</span><br></pre></td></tr></table></figure>

<p>加载网络模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载网络模型</span></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> *</span><br><span class="line">model = torch.load(<span class="string">&quot;td_model_0.pth&quot;</span>,map_location=torch.device(<span class="string">&#x27;cpu&#x27;</span>), weights_only=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="comment"># 注意此时引用的模型文件是用gpu训练的，如果测试时使用的是cpu，则需要指定设备到cpu去运算</span></span><br></pre></td></tr></table></figure>

<p>输入图片，推理结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">image = torch.reshape(image, (<span class="number">1</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">model.<span class="built_in">eval</span>()            <span class="comment"># 用于将模型设置为评估模式。</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():   <span class="comment"># 禁用梯度计算（节省内存，加速推理）。</span></span><br><span class="line">    output = model(image)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="built_in">print</span>(output.argmax(dim=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/ye_source/avatar1.webp" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/ye_source/avatar1.webp" title="头像" alt="头像"></a><div class="post-copyright__author_name">山河忽晚</div><div class="post-copyright__author_desc">落落冰川流转着千年古忆</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="https://www.dyeddie.top/20250603/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('https://www.dyeddie.top/20250603/')">初识Pytorch(三) -- 完整的模型训练流程 + GPU调用训练</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="https://www.dyeddie.top/20250603/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.dyeddie.top" target="_blank">枫落繁花</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/Pytorch/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>Pytorch<span class="tagsPageCount">4</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="https://www.dyeddie.top/20250628/wallhaven-zy1wrg_compressed.jpg" data-sites="facebook,twitter,wechat,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/20250602/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://www.dyeddie.top/20250602/110119t32pt.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">初识Pytorch(二) -- 神经网络搭建</div></div></a></div><div class="next-post pull-right"><a href="/20250628/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://www.dyeddie.top/20250628/wallhaven-zy1wrg_compressed.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">动手学深度学习1--预备知识</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/20250601/" title="初识Pytorch(一) -- Transforms笔记"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://www.dyeddie.top/20250601/1800483AlZN.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-06-03</div><div class="title">初识Pytorch(一) -- Transforms笔记</div></div></a></div><div><a href="/20250602/" title="初识Pytorch(二) -- 神经网络搭建"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://www.dyeddie.top/20250602/110119t32pt.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-06-03</div><div class="title">初识Pytorch(二) -- 神经网络搭建</div></div></a></div><div><a href="/20250628/" title="动手学深度学习1--预备知识"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://www.dyeddie.top/20250628/wallhaven-zy1wrg_compressed.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-06-28</div><div class="title">动手学深度学习1--预备知识</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E6%9E%84%E5%BB%BA%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-text">1 构建训练模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E5%AF%BC%E5%85%A5torch%E6%A8%A1%E5%9D%97"><span class="toc-text">1.1 导入torch模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">1.2 准备数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F"><span class="toc-text">1.3 查看数据集的大小</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">1.4 加载数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-%E6%90%AD%E5%BB%BA%E6%A8%A1%E5%9E%8B"><span class="toc-text">1.5 搭建模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-6-%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="toc-text">1.6 训练参数设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-7-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95"><span class="toc-text">1.7 模型训练与测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-8-%E6%AD%A3%E7%A1%AE%E7%8E%87-%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-text">1.8 正确率(分类问题)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-9-%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="toc-text">1.9 完整代码</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E4%BD%BF%E7%94%A8-GPU-%E8%AE%AD%E7%BB%83"><span class="toc-text">2 使用 GPU 训练</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E8%B0%83%E7%94%A8%E6%96%B9%E5%BC%8F-1"><span class="toc-text">2.1 调用方式 1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E8%B0%83%E7%94%A8%E6%96%B9%E5%BC%8F-2"><span class="toc-text">2.2 调用方式 2</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%9C"><span class="toc-text">3 测试模型结果</span></a></li></ol></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title="博客框架为Hexo_v5.4.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/ye_source/bottom_footer/Frame-Hexo.svg" alt="博客框架为Hexo_v5.4.0"/></a><a class="github-badge" target="_blank" href="https://blog.anheyu.com/" style="margin-inline:5px" data-title="本站使用AnZhiYu主题" title="本站使用AnZhiYu主题"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/ye_source/bottom_footer/Theme-AnZhiYu-2E67D3.svg" alt="本站使用AnZhiYu主题"/></a><a class="github-badge" target="_blank" href="https://www.dogecloud.com/" style="margin-inline:5px" data-title="本站使用多吉云为静态资源提供CDN加速" title="本站使用多吉云为静态资源提供CDN加速"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/ye_source/bottom_footer/CDN-多吉云-3693F3.svg" alt="本站使用多吉云为静态资源提供CDN加速"/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title="本站项目由Github托管"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/ye_source/bottom_footer/Source-Github.svg" alt="本站项目由Github托管"/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/ye_source/bottom_footer/Copyright-BY-NC-SA.svg" alt="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"/></a></p></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2024 - 2025 By <a class="footer-bar-link" href="/" title="山河忽晚" target="_blank">山河忽晚</a></div></div><div id="footer-type-tips"></div><div class="js-pjax"><script>function subtitleType () {
  fetch('https://v1.hitokoto.cn')
    .then(response => response.json())
    .then(data => {
      if (true) {
        const from = '出自 ' + data.from
        const sub = []
        sub.unshift(data.hitokoto, from)
        window.typed = new Typed('#footer-type-tips', {
          strings: sub,
          startDelay: 300,
          typeSpeed: 150,
          loop: true,
          backSpeed: 50,
        })
      } else {
        document.getElementById('footer-type-tips').innerHTML = data.hitokoto
      }
    })
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.cbd.int/typed.js@2.1.0/dist/typed.umd.js').then(subtitleType)
  }
} else {
  subtitleType()
}
</script></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" title="冀ICP备-2024076436号">冀ICP备-2024076436号</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">6</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">其他</div><div class="back-menu-list"><a class="back-menu-item" href="/archives/" title="文章归档"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/ye_source/archieves.jpg" alt="文章归档"/><span class="back-menu-item-text">文章归档</span></a><a class="back-menu-item" href="/music/?id=3778678&amp;server=netease" title="听力练习"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/ye_source/de36c853a5ea9.jpg" alt="听力练习"/><span class="back-menu-item-text">听力练习</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 类别</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 解压</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/?id=3778678&amp;server=netease"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/apps/"><i class="fa-brands fa-canadian-maple-leaf faa-tada"></i><span> 修仙室</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> About</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/ArchLinux/" style="font-size: 0.88rem; color: rgb(120, 134, 180);">ArchLinux<sup>1</sup></a><a href="/tags/GitHub/" style="font-size: 0.88rem; color: rgb(55, 31, 86);">GitHub<sup>2</sup></a><a href="/tags/Linux/" style="font-size: 0.88rem; color: rgb(76, 175, 181);">Linux<sup>5</sup></a><a href="/tags/Numpy/" style="font-size: 0.88rem; color: rgb(126, 184, 173);">Numpy<sup>1</sup></a><a href="/tags/Oral-Practice/" style="font-size: 0.88rem; color: rgb(179, 117, 2);">Oral_Practice<sup>2</sup></a><a href="/tags/Python/" style="font-size: 0.88rem; color: rgb(56, 165, 197);">Python<sup>1</sup></a><a href="/tags/Pytorch/" style="font-size: 0.88rem; color: rgb(100, 58, 13);">Pytorch<sup>4</sup></a><a href="/tags/Skills/" style="font-size: 0.88rem; color: rgb(106, 72, 121);">Skills<sup>1</sup></a><a href="/tags/Sublime-Text/" style="font-size: 0.88rem; color: rgb(179, 33, 45);">Sublime_Text<sup>1</sup></a><a href="/tags/Ubuntu/" style="font-size: 0.88rem; color: rgb(183, 10, 174);">Ubuntu<sup>2</sup></a><a href="/tags/Xfce/" style="font-size: 0.88rem; color: rgb(22, 118, 123);">Xfce<sup>1</sup></a><a href="/tags/conda%E5%91%BD%E4%BB%A4/" style="font-size: 0.88rem; color: rgb(41, 88, 141);">conda命令<sup>1</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("05/01/2024 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2024 By 安知鱼 V1.6.12",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 山河忽晚 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><input type="hidden" name="page-type" id="page-type" value="post"></div><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: true,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', 'G-3RZJMX45BS', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>